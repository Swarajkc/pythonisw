{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0f5367-ddb0-4f33-a7c2-98b7ca300b5e",
   "metadata": {},
   "source": [
    "# Pandas Data Series\n",
    "\n",
    "1. Write a Pandas program to create and display a one-dimensional array-like object containing an array of data using Pandas module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d8efc00-e33b-4c9e-8268-b1fc908808b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds = pd.Series([1,2,3,4,5])\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7545a96-e03b-498a-89c5-71a86a8574d9",
   "metadata": {},
   "source": [
    "2. Write a Pandas program to convert a Panda module Series to Python list and it's type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4dea3f6-142f-4565-b194-abe540dde44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas series and type\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "converting to list\n",
      "[1, 2, 3, 4, 5]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds = pd.Series([1,2,3,4,5])\n",
    "print(\"pandas series and type\")\n",
    "print(ds)\n",
    "print(type(ds))\n",
    "print(\"converting to list\")\n",
    "print(ds.tolist())\n",
    "print(type(ds.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0ba7cc-6536-4148-aaf1-031ac5787457",
   "metadata": {},
   "source": [
    "3. Write a Pandas program to add, subtract, multiple and divide two Pandas Series.\n",
    "Sample Series: [2, 4, 6, 8, 10], [1, 3, 5, 7, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5b9850-66b1-4da2-a90d-39ac22fb4fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add two series\n",
      "0     3\n",
      "1     7\n",
      "2    11\n",
      "3    15\n",
      "4    19\n",
      "dtype: int64\n",
      "Subtract two series\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "dtype: int64\n",
      "multiply two series\n",
      "0     2\n",
      "1    12\n",
      "2    30\n",
      "3    56\n",
      "4    90\n",
      "dtype: int64\n",
      "Divide two series\n",
      "0    2.000000\n",
      "1    1.333333\n",
      "2    1.200000\n",
      "3    1.142857\n",
      "4    1.111111\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ds1 = pd.Series([2, 4, 6, 8, 10])\n",
    "ds2 = pd.Series([1, 3, 5, 7, 9])\n",
    "\n",
    "ds = ds1+ds2\n",
    "print(\"Add two series\")\n",
    "print(ds)\n",
    "\n",
    "print(\"Subtract two series\")\n",
    "ds = ds1-ds2\n",
    "print(ds)\n",
    "\n",
    "print(\"multiply two series\")\n",
    "ds = ds1 * ds2\n",
    "print(ds)\n",
    "\n",
    "print(\"Divide two series\")\n",
    "ds = ds1/ds2\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19997a0-a931-4e74-8154-cca070ab99c9",
   "metadata": {},
   "source": [
    "4. Write a Pandas program to compare the elements of the two Pandas Series.\n",
    "Sample Series: [2, 4, 6, 8, 10], [1, 3, 5, 7, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7b2005-1dca-444b-ae30-19b0b8b87cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series1:\n",
      "0     2\n",
      "1     4\n",
      "2     6\n",
      "3     8\n",
      "4    10\n",
      "dtype: int64\n",
      "Series2:\n",
      "0     1\n",
      "1     3\n",
      "2     5\n",
      "3     7\n",
      "4    10\n",
      "dtype: int64\n",
      "Compare the elements of the said Series:\n",
      "Equals:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n",
      "Greater than:\n",
      "0     True\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4    False\n",
      "dtype: bool\n",
      "Less than:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ds1 = pd.Series([2, 4, 6, 8, 10])\n",
    "ds2 = pd.Series([1, 3, 5, 7, 10])\n",
    "\n",
    "print(\"Series1:\")\n",
    "print(ds1)\n",
    "print(\"Series2:\")\n",
    "print(ds2)\n",
    "\n",
    "print(\"Compare the elements of the said Series:\")\n",
    "\n",
    "print(\"Equals:\")\n",
    "print(ds1 == ds2)\n",
    "\n",
    "print(\"Greater than:\")\n",
    "print(ds1 > ds2)\n",
    "\n",
    "print(\"Less than:\")\n",
    "print(ds1 < ds2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcdb293-529c-4156-8b9b-450ded79bc2f",
   "metadata": {},
   "source": [
    "5. Write a Pandas program to convert a dictionary to a Pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b0c8732-6bba-48e9-b523-964b31000a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dictionary:\n",
      "{'a': 100, 'b': 200, 'c': 300, 'd': 400, 'e': 800}\n",
      "Converted series:\n",
      "a    100\n",
      "b    200\n",
      "c    300\n",
      "d    400\n",
      "e    800\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "d = {'a': 100, 'b': 200, 'c': 300, 'd': 400, 'e': 800}\n",
    "print(\"Original dictionary:\")\n",
    "print(d)\n",
    "\n",
    "df = pd.Series(d)\n",
    "print(\"Converted series:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c14ffe-663e-4f62-a59c-5e5de49ea07b",
   "metadata": {},
   "source": [
    "6. Write a Pandas program to convert a NumPy array to a Pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e94b98-7e6d-4505-8259-e9636df54822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array:\n",
      "[10 20 30 40 50]\n",
      "Converted Pandas series:\n",
      "0    10\n",
      "1    20\n",
      "2    30\n",
      "3    40\n",
      "4    50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np_array = np.array([10, 20, 30, 40, 50])\n",
    "print(\"NumPy array:\")\n",
    "print(np_array)\n",
    "\n",
    "new_series = pd.Series(np_array)\n",
    "print(\"Converted Pandas series:\")\n",
    "print(new_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b315735-f887-4336-b2f6-b1e235309085",
   "metadata": {},
   "source": [
    "7. Write a Pandas program to change the data type of given a column or a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7132ef5f-9bb5-4cd0-aec1-9bdb920b9111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Series:\n",
      "0       100\n",
      "1       200\n",
      "2    python\n",
      "3    300.12\n",
      "4       400\n",
      "dtype: object\n",
      "Change the said data type to numeric:\n",
      "0    100.00\n",
      "1    200.00\n",
      "2       NaN\n",
      "3    300.12\n",
      "4    400.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "s1 = pd.Series(['100', '200', 'python', '300.12', '400'])\n",
    "print(\"Original Data Series:\")\n",
    "print(s1)\n",
    "print(\"Change the said data type to numeric:\")\n",
    "s2 = pd.to_numeric(s1, errors='coerce')\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b478f100-d46c-4d0a-93f2-95778ea6c2db",
   "metadata": {},
   "source": [
    "8. Write a Pandas program to convert the first column of a DataFrame as a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cef95fb-8464-40c7-a25f-65ec44832d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame\n",
      "   col1  col2  col3\n",
      "0     1     4     7\n",
      "1     2     5     5\n",
      "2     3     6     8\n",
      "3     4     9    12\n",
      "4     7     5     1\n",
      "5    11     0    11\n",
      "\n",
      "1st column as a Series:\n",
      "0     1\n",
      "1     2\n",
      "2     3\n",
      "3     4\n",
      "4     7\n",
      "5    11\n",
      "Name: col1, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {'col1': [1, 2, 3, 4, 7, 11], 'col2': [4, 5, 6, 9, 5, 0], 'col3': [7, 5, 8, 12, 1, 11]}\n",
    "df = pd.DataFrame(d)\n",
    "\n",
    "print(\"Original DataFrame\")\n",
    "print(df)\n",
    "\n",
    "# Using iloc\n",
    "s1 = df.iloc[:, 0]\n",
    "print(\"\\n1st column as a Series:\")\n",
    "print(s1)\n",
    "print(type(s1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d97c05-a2df-48bd-813a-b60b34872b69",
   "metadata": {},
   "source": [
    "9. Write a Pandas program to convert a given Series to an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7de41da8-f57e-4cfe-97fd-3ee0303d2147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Series:\n",
      "0       100\n",
      "1       200\n",
      "2    python\n",
      "3    300.12\n",
      "4       400\n",
      "dtype: object\n",
      "Series to an array\n",
      "['100' '200' 'python' '300.12' '400']\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "s1 = pd.Series(['100', '200', 'python', '300.12', '400'])\n",
    "print(\"Original Data Series:\")\n",
    "print(s1)\n",
    "print(\"Series to an array\")\n",
    "a = s1.values\n",
    "print(a)\n",
    "print(type(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f993558-5e71-405e-a906-61769d5b5dbf",
   "metadata": {},
   "source": [
    "10. Write a Pandas program to convert Series of lists to one Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6118958c-81e4-4206-8d60-f7759375e17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series of list\n",
      "0    [Red, Green, White]\n",
      "1           [Red, Black]\n",
      "2               [Yellow]\n",
      "dtype: object\n",
      "One Series\n",
      "0       Red\n",
      "1     Green\n",
      "2     White\n",
      "3       Red\n",
      "4     Black\n",
      "5    Yellow\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "s = pd.Series([\n",
    "    ['Red', 'Green', 'White'],\n",
    "    ['Red', 'Black'],\n",
    "    ['Yellow']])\n",
    "print(\"Original Series of list\")\n",
    "print(s)\n",
    "s = s.apply(pd.Series).stack().reset_index(drop=True)\n",
    "print(\"One Series\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2764cdb-f03f-48f5-b509-26bde3de3dac",
   "metadata": {},
   "source": [
    "# Pandas DataFrame\n",
    "\n",
    "1. Write a Pandas program to create a dataframe from a dictionary and display it.\n",
    "Sample data: {'X':[78,85,96,80,86], 'Y':[84,94,89,83,86],'Z':[86,97,96,72,83]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "804102f9-5bcc-4ecc-a99d-412ef726836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X   Y   Z\n",
      "0  78  84  86\n",
      "1  85  94  97\n",
      "2  96  89  96\n",
      "3  80  83  72\n",
      "4  86  86  83\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data =  {'X':[78,85,96,80,86], 'Y':[84,94,89,83,86],'Z':[86,97,96,72,83]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9492b24-80b6-4bc9-b036-c235dca1d4f7",
   "metadata": {},
   "source": [
    "2. Write a Pandas program to create and display a DataFrame from a specified dictionary data which has the index labels.\n",
    "- Sample Python dictionary data and list labels:\n",
    "- exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "- 'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "- 'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "- 'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "- labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27d3c29f-78ad-4810-bea5-a10e8878296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name  score  attempts qualify\n",
      "a  Anastasia   12.5         1     yes\n",
      "b       Dima    9.0         3      no\n",
      "c  Katherine   16.5         2     yes\n",
      "d      James    NaN         3      no\n",
      "e      Emily    9.0         2      no\n",
      "f    Michael   20.0         3     yes\n",
      "g    Matthew   14.5         1     yes\n",
      "h      Laura    NaN         1      no\n",
      "i      Kevin    8.0         2      no\n",
      "j      Jonas   19.0         1     yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9abdf4b-91ad-4e4d-bc5d-acc7dc31036c",
   "metadata": {},
   "source": [
    "3. Write a Pandas program to display a summary of the basic information about a specified DataFrame and its data.\n",
    "<br>Sample Python dictionary data and list labels:\n",
    "- exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "- 'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "- 'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "- 'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "- labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99633111-aac9-4a21-bd36-ad1b69e0e0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the basic information about this DataFrame and its data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10 entries, a to j\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   name      10 non-null     object \n",
      " 1   score     8 non-null      float64\n",
      " 2   attempts  10 non-null     int64  \n",
      " 3   qualify   10 non-null     object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 400.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "print(\"Summary of the basic information about this DataFrame and its data:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9741a-e55b-4923-b9c7-b5b0a8fec8d7",
   "metadata": {},
   "source": [
    "4. Write a Pandas program to get the first 3 rows of a given DataFrame.\n",
    "- Sample Python dictionary data and list labels:\n",
    "- exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "- 'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "- 'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "- 'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "- labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "033a2ad8-3a5f-4f89-9e3a-6326f9b5b5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First three rows of the data frame:\n",
      "        name  score  attempts qualify\n",
      "a  Anastasia   12.5         1     yes\n",
      "b       Dima    9.0         3      no\n",
      "c  Katherine   16.5         2     yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "print(\"First three rows of the data frame:\")\n",
    "print(df.iloc[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a8444c-8d61-4e88-a54a-7fde41b64124",
   "metadata": {},
   "source": [
    "5. Write a Pandas program to select the 'name' and 'score' columns from the following DataFrame.\n",
    "- Sample Python dictionary data and list labels:\n",
    "- exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "- 'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "- 'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "- 'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "- labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1c4a3ba-230b-4cf6-aa9c-1223c544fa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select specific columns:\n",
      "        name  score\n",
      "a  Anastasia   12.5\n",
      "b       Dima    9.0\n",
      "c  Katherine   16.5\n",
      "d      James    NaN\n",
      "e      Emily    9.0\n",
      "f    Michael   20.0\n",
      "g    Matthew   14.5\n",
      "h      Laura    NaN\n",
      "i      Kevin    8.0\n",
      "j      Jonas   19.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "print(\"Select specific columns:\")\n",
    "print(df[['name', 'score']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a7881-18ce-486e-bba6-f673f1e21125",
   "metadata": {},
   "source": [
    "6. Write a Pandas program to select the specified columns and rows from a given data frame.\n",
    "- Sample Python dictionary data and list labels:\n",
    "- Select 'name' and 'score' columns in rows 1, 3, 5, 6 from the following data frame.\n",
    "- exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "\n",
    "\n",
    "- 'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "- 'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "- 'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "- labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55c54656-0134-47d8-997d-e17bf5184c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select specific columns and rows:\n",
      "      name  score\n",
      "b     Dima    9.0\n",
      "d    James    NaN\n",
      "f  Michael   20.0\n",
      "g  Matthew   14.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "print(\"Select specific columns and rows:\")\n",
    "print(df.iloc[[1, 3, 5, 6], [0,1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c7a60-54ac-4e85-a202-e0fbba12683a",
   "metadata": {},
   "source": [
    "7. Write a  Pandas program to select the rows where the number of attempts in the examination is greater than 2.\n",
    "- Sample Python dictionary data and list labels:\n",
    "- exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "- 'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "- 'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "- 'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "- labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5ffa979-5d44-4e67-a06a-00ea8f4f74da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of attempts in the examination is greater than 2:\n",
      "      name  score  attempts qualify\n",
      "b     Dima    9.0         3      no\n",
      "d    James    NaN         3      no\n",
      "f  Michael   20.0         3     yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        'attempts' : [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "print(\"Number of attempts in the examination is greater than 2:\")\n",
    "print(df[df['attempts'] > 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cabad3-e458-40d6-b5c0-e967151dd8af",
   "metadata": {},
   "source": [
    "8. Write a Pandas program to count the number of rows and columns of a DataFrame.\n",
    "- Sample  Python dictionary data and list labels:\n",
    "- exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "- 'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "- 'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "- 'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "- labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46312462-d071-4a50-9a91-deb2b18f4b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows:  10\n",
      "Number of Columns:  4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "total_rows=len(df.axes[0])\n",
    "total_cols=len(df.axes[1])\n",
    "print(\"Number of Rows: \",total_rows)\n",
    "print(\"Number of Columns: \",total_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd3389-e214-43f7-b06a-11b4678a8db2",
   "metadata": {},
   "source": [
    "9. Write a Pandas program to select the rows where the score is missing, i.e. is NaN.\n",
    "- Sample Python dictionary data and list labels:\n",
    "- exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "- 'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "- 'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "- 'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "- labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96002d82-e8c2-4726-9d5e-5d7de838864d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where score is missing:\n",
      "    name  score  attempts qualify\n",
      "d  James    NaN         3      no\n",
      "h  Laura    NaN         1      no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "print(\"Rows where score is missing:\")\n",
    "print(df[df['score'].isnull()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0730f-6834-4651-a0bb-3fd05c7f5219",
   "metadata": {},
   "source": [
    "10. Write a Pandas program to select the rows the score is between 15 and 20 (inclusive).\n",
    "- Sample Python dictionary data and list labels:\n",
    "- exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "- 'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "- 'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "- 'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "- labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35d15038-821f-4cee-adec-248c6143a1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score between 15 and 20\n",
      "        name  score  attempts qualify\n",
      "c  Katherine   16.5         2     yes\n",
      "f    Michael   20.0         3     yes\n",
      "j      Jonas   19.0         1     yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "    'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "    'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "    'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data, index = labels)\n",
    "\n",
    "print(\"score between 15 and 20\")\n",
    "print(df[df['score'].between(15, 20)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53580225-9836-495d-bf5b-366fa242b918",
   "metadata": {},
   "source": [
    "# Pandas Index\n",
    "\n",
    "1. Write a Pandas program to display the default index and set a column as an Index in a given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ffa31e7-abd3-486b-93d9-affee21f0265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Index:\n",
      "  school_code class            name date_Of_Birth  weight  address t_id\n",
      "0        s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "1        s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "2        s003    VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
      "3        s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "4        s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "5        s004    VI    David Parkes    15/09/1997      32  street4   t6\n",
      "\n",
      "school_code as new Index:\n",
      "            class            name date_Of_Birth  weight  address t_id\n",
      "school_code                                                          \n",
      "s001            V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "s002            V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "s003           VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
      "s001           VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "s002            V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "s004           VI    David Parkes    15/09/1997      32  street4   t6\n",
      "\n",
      "t_id as new Index:\n",
      "     school_code class            name date_Of_Birth  weight  address\n",
      "t_id                                                                 \n",
      "t1          s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "t2          s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "t3          s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "t4          s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "t5          s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "t6          s004    VI    David Parkes    15/09/1997      32  street4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "print(\"Default Index:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nschool_code as new Index:\")\n",
    "df1 = df.set_index('school_code')\n",
    "print(df1)\n",
    "print(\"\\nt_id as new Index:\")\n",
    "df2 = df.set_index('t_id')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8a7ac-80c8-4fa4-a809-6ade47bae62f",
   "metadata": {},
   "source": [
    "2. Write a Pandas program to create a multi Index frame using two columns and using an Index and a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96d0c2cf-4097-4dc7-b663-e7c8194f60da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  school_code class            name date_Of_Birth  weight  address t_id\n",
      "0        s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "1        s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "2        s003    VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
      "3        s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "4        s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "5        s004    VI    David Parkes    15/09/1997      32  street4   t6\n",
      "\n",
      "MultiIndex using columns 't_id' and ‘school_code’:\n",
      "                 class            name date_Of_Birth  weight  address\n",
      "t_id school_code                                                     \n",
      "t1   s001            V  Alberto Franco    15/05/2002      35  street1\n",
      "t2   s002            V    Gino Mcneill    17/05/2002      32  street2\n",
      "t3   s003           VI     Ryan Parkes    16/02/1999      33  street3\n",
      "t4   s001           VI    Eesha Hinton    25/09/1998      30  street1\n",
      "t5   s002            V    Gino Mcneill    11/05/2002      31  street2\n",
      "t6   s004           VI    David Parkes    15/09/1997      32  street4\n",
      "\n",
      "MultiIndex using an Index and a column:\n",
      "       school_code class            name date_Of_Birth  weight  address\n",
      "  t_id                                                                 \n",
      "0 t1          s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "1 t2          s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "2 t3          s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "3 t4          s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "4 t5          s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "5 t6          s004    VI    David Parkes    15/09/1997      32  street4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nMultiIndex using columns 't_id' and ‘school_code’:\")\n",
    "df1 = df.set_index(['t_id', 'school_code'])\n",
    "print(df1)\n",
    "print(\"\\nMultiIndex using an Index and a column:\")\n",
    "df2 = df.set_index([pd.Index([0, 1, 2, 3, 4, 5]), 't_id'])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07fd75-fa77-46b8-a970-1dd3cc97344e",
   "metadata": {},
   "source": [
    "3. Write a Pandas program to display the default index and set a column as an Index in a given dataframe and then reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cf3f957-449e-4bb3-80c2-dd519be30b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Index:\n",
      "  school_code class            name date_Of_Birth  weight  address t_id\n",
      "0        s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "1        s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "2        s003    VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
      "3        s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "4        s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "5        s004    VI    David Parkes    15/09/1997      32  street4   t6\n",
      "\n",
      "t_id as new Index:\n",
      "     school_code class            name date_Of_Birth  weight  address\n",
      "t_id                                                                 \n",
      "t1          s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "t2          s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "t3          s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "t4          s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "t5          s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "t6          s004    VI    David Parkes    15/09/1997      32  street4\n",
      "\n",
      "Reset the index:\n",
      "  t_id school_code class            name date_Of_Birth  weight  address\n",
      "0   t1        s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "1   t2        s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "2   t3        s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "3   t4        s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "4   t5        s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "5   t6        s004    VI    David Parkes    15/09/1997      32  street4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "print(\"Default Index:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nt_id as new Index:\")\n",
    "df1 = df.set_index('t_id')\n",
    "print(df1)\n",
    "print(\"\\nReset the index:\")\n",
    "df2 = df1.reset_index(inplace=False)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1cc99d-4e7c-4673-9e76-7d39b1103891",
   "metadata": {},
   "source": [
    "4. Write a Pandas program to create an index labels by using 64-bit integers, using floating-point numbers in a given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dda9d765-96e8-4123-ab03-ec8477a646d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an Int64Index:\n",
      "  school_code class            name date_Of_Birth  weight  address\n",
      "1        s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "2        s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "3        s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "4        s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "5        s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "6        s004    VI    David Parkes    15/09/1997      32  street4\n",
      "\n",
      "View the Index:\n",
      "Index([1, 2, 3, 4, 5, 6], dtype='int64')\n",
      "\n",
      "Floating-point labels using Float64Index:\n",
      "    school_code class            name date_Of_Birth   weight  address\n",
      "0.1        s001     V  Alberto Franco     15/05/2002      35  street1\n",
      "0.2        s002     V    Gino Mcneill     17/05/2002      32  street2\n",
      "0.3        s003    VI     Ryan Parkes     16/02/1999      33  street3\n",
      "0.4        s001    VI    Eesha Hinton     25/09/1998      30  street1\n",
      "0.5        s002     V    Gino Mcneill     11/05/2002      31  street2\n",
      "0.6        s004    VI    David Parkes     15/09/1997      32  street4\n",
      "\n",
      "View the Index:\n",
      "Index([0.1, 0.2, 0.3, 0.4, 0.5, 0.6], dtype='float64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Create an Int64Index:\")\n",
    "df_i64 = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=[1, 2, 3, 4, 5, 6])\n",
    "print(df_i64)\n",
    "print(\"\\nView the Index:\")\n",
    "print(df_i64.index)\n",
    "\n",
    "print(\"\\nFloating-point labels using Float64Index:\")\n",
    "df_f64 = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=[.1, .2, .3, .4, .5, .6])\n",
    "print(df_f64)\n",
    "print(\"\\nView the Index:\")\n",
    "print(df_f64.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af488e2-944c-4ce7-9e3a-8491ab7595ed",
   "metadata": {},
   "source": [
    "5. Write a Pandas program to create a DataFrame using intervals as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f99982d8-46aa-4e85-b4fa-79771d1fe230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an Interval Index using IntervalIndex.from_breaks:\n",
      "            X\n",
      "(0.0, 0.5]  1\n",
      "(0.5, 1.0]  2\n",
      "(1.0, 1.5]  3\n",
      "(1.5, 2.0]  4\n",
      "(2.0, 2.5]  5\n",
      "(2.5, 3.0]  6\n",
      "(3.0, 3.5]  7\n",
      "IntervalIndex([(0.0, 0.5], (0.5, 1.0], (1.0, 1.5], (1.5, 2.0], (2.0, 2.5],\n",
      "               (2.5, 3.0], (3.0, 3.5]],\n",
      "              dtype='interval[float64, right]')\n",
      "\n",
      "Create an Interval Index using IntervalIndex.from_tuples:\n",
      "            X\n",
      "(0.0, 0.5]  1\n",
      "(0.5, 1.0]  2\n",
      "(1.0, 1.5]  3\n",
      "(1.5, 2.0]  4\n",
      "(2.0, 2.5]  5\n",
      "(2.5, 3.0]  6\n",
      "(3.0, 3.5]  7\n",
      "IntervalIndex([(0.0, 0.5], (0.5, 1.0], (1.0, 1.5], (1.5, 2.0], (2.0, 2.5],\n",
      "               (2.5, 3.0], (3.0, 3.5]],\n",
      "              dtype='interval[float64, right]')\n",
      "\n",
      "Create an Interval Index using IntervalIndex.from_arrays:\n",
      "            X\n",
      "(0.0, 0.5]  1\n",
      "(0.5, 1.0]  2\n",
      "(1.0, 1.5]  3\n",
      "(1.5, 2.0]  4\n",
      "(2.0, 2.5]  5\n",
      "(2.5, 3.0]  6\n",
      "(3.0, 3.5]  7\n",
      "IntervalIndex([(0.0, 0.5], (0.5, 1.0], (1.0, 1.5], (1.5, 2.0], (2.0, 2.5],\n",
      "               (2.5, 3.0], (3.0, 3.5]],\n",
      "              dtype='interval[float64, right]')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Create an Interval Index using IntervalIndex.from_breaks:\")\n",
    "df_interval = pd.DataFrame({\"X\":[1, 2, 3, 4, 5, 6, 7]},\n",
    "                            index = pd.IntervalIndex.from_breaks(\n",
    "                            [0, 0.5, 1.0, 1.5, 2.0, 2.5, 3, 3.5]))    \n",
    "print(df_interval)\n",
    "print(df_interval.index)\n",
    "\n",
    "print(\"\\nCreate an Interval Index using IntervalIndex.from_tuples:\")\n",
    "df_interval = pd.DataFrame({\"X\":[1, 2, 3, 4, 5, 6, 7]},             \n",
    "                            index = pd.IntervalIndex.from_tuples(\n",
    "                            [(0, .5), (.5, 1), (1, 1.5), (1.5, 2), (2, 2.5), (2.5, 3), (3, 3.5)]))\n",
    "print(df_interval)\n",
    "print(df_interval.index)\n",
    "\n",
    "print(\"\\nCreate an Interval Index using IntervalIndex.from_arrays:\")\n",
    "df_interval = pd.DataFrame({\"X\":[1, 2, 3, 4, 5, 6, 7]},             \n",
    "                            index = pd.IntervalIndex.from_arrays(\n",
    "                            [0, .5, 1, 1.5, 2, 2.5, 3], [.5, 1, 1.5, 2, 2.5, 3, 3.5]))\n",
    "print(df_interval)\n",
    "print(df_interval.index) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642fe565-f220-4416-8d04-8f48ed21f9e1",
   "metadata": {},
   "source": [
    "# Pandas String And Regular Expression\n",
    "\n",
    "1. Write a Pandas program to convert all the string values to upper, lower cases in a given pandas series. Also find the length of the string values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b28c5b3f-54b8-4b32-a257-b1d68547bfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original series:\n",
      "0         X\n",
      "1         Y\n",
      "2         Z\n",
      "3      Aaba\n",
      "4      Baca\n",
      "5       NaN\n",
      "6      CABA\n",
      "7      None\n",
      "8      bird\n",
      "9     horse\n",
      "10      dog\n",
      "dtype: object\n",
      "\n",
      "Convert all string values of the said Series to upper case:\n",
      "0         X\n",
      "1         Y\n",
      "2         Z\n",
      "3      AABA\n",
      "4      BACA\n",
      "5       NaN\n",
      "6      CABA\n",
      "7      None\n",
      "8      BIRD\n",
      "9     HORSE\n",
      "10      DOG\n",
      "dtype: object\n",
      "\n",
      "Convert all string values of the said Series to lower case:\n",
      "0         x\n",
      "1         y\n",
      "2         z\n",
      "3      aaba\n",
      "4      baca\n",
      "5       NaN\n",
      "6      caba\n",
      "7      None\n",
      "8      bird\n",
      "9     horse\n",
      "10      dog\n",
      "dtype: object\n",
      "\n",
      "leng of the string values:\n",
      "0     1.0\n",
      "1     1.0\n",
      "2     1.0\n",
      "3     4.0\n",
      "4     4.0\n",
      "5     NaN\n",
      "6     4.0\n",
      "7     NaN\n",
      "8     4.0\n",
      "9     5.0\n",
      "10    3.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "s = pd.Series(['X', 'Y', 'Z', 'Aaba', 'Baca', np.nan, 'CABA', None, 'bird', 'horse', 'dog'])\n",
    "print(\"Original series:\")\n",
    "print(s)\n",
    "print(\"\\nConvert all string values of the said Series to upper case:\")\n",
    "print(s.str.upper())\n",
    "print(\"\\nConvert all string values of the said Series to lower case:\")\n",
    "print(s.str.lower())\n",
    "print(\"\\nleng of the string values:\")\n",
    "print(s.str.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3445a6-cc34-4b59-ae82-bcaaafa33a1a",
   "metadata": {},
   "source": [
    "2. Write a Pandas program to remove whitespaces, left sided whitespaces and right sided whitespaces of the string values of a given pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bf5cfde-7a98-41d5-9047-f205a7f52fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original series:\n",
      "0     Green\n",
      "1    Black \n",
      "2      Red \n",
      "3     White\n",
      "4     Pink \n",
      "dtype: object\n",
      "\n",
      "Remove whitespace\n",
      "0    Green\n",
      "1    Black\n",
      "2      Red\n",
      "3    White\n",
      "4     Pink\n",
      "dtype: object\n",
      "\n",
      "Remove left sided whitespace\n",
      "0     Green\n",
      "1    Black \n",
      "2      Red \n",
      "3     White\n",
      "4     Pink \n",
      "dtype: object\n",
      "\n",
      "Remove Right sided whitespace\n",
      "0     Green\n",
      "1     Black\n",
      "2       Red\n",
      "3     White\n",
      "4      Pink\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "color1 = pd.Series([' Green', 'Black ', ' Red ', 'White', ' Pink '])\n",
    "print(\"Original series:\")\n",
    "print(color1)\n",
    "print(\"\\nRemove whitespace\")\n",
    "print(color1.str.strip())\n",
    "print(\"\\nRemove left sided whitespace\")\n",
    "print(color1.str.lstrip())\n",
    "print(\"\\nRemove Right sided whitespace\")\n",
    "print(color1.str.rstrip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67900950-0974-45de-adb0-86d820f689d6",
   "metadata": {},
   "source": [
    "3. Write a Pandas program to add leading zeros to the integer column in a pandas series and makes the length of the field to 8 digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d20db9cf-81bc-4dde-9121-c696bb7e3b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe:\n",
      "   amount\n",
      "0      10\n",
      "1     250\n",
      "2    3000\n",
      "3   40000\n",
      "4  500000\n",
      "\n",
      "Add leading zeros:\n",
      "     amount\n",
      "0  00000010\n",
      "1  00000250\n",
      "2  00003000\n",
      "3  00040000\n",
      "4  00500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nums = {'amount': [10, 250, 3000, 40000, 500000]}\n",
    "print(\"Original dataframe:\")\n",
    "df = pd.DataFrame(nums)\n",
    "print(df)\n",
    "print(\"\\nAdd leading zeros:\")\n",
    "df['amount'] = df['amount'].apply(lambda x: '{0:0>8}'.format(x))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "128faa0d-79c1-4f27-a3b5-79fe40e11f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe:\n",
      "   amount\n",
      "0      10\n",
      "1     250\n",
      "2    3000\n",
      "3   40000\n",
      "4  500000\n",
      "\n",
      "Add leading zeros:\n",
      "     amount\n",
      "0  00000010\n",
      "1  00000250\n",
      "2  00003000\n",
      "3  00040000\n",
      "4  00500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nums = {'amount': [10, 250, 3000, 40000, 500000]}\n",
    "df = pd.DataFrame(nums)\n",
    "\n",
    "print(\"Original dataframe:\")\n",
    "print(df)\n",
    "\n",
    "df['amount'] = df['amount'].astype(str).str.zfill(8)\n",
    "\n",
    "print(\"\\nAdd leading zeros:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d51105-c956-41c5-8bdc-687b1b772eca",
   "metadata": {},
   "source": [
    "4. Write a Pandas program to capitalize all the string values of specified columns of a given DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d480d80-29a0-4e84-bdb5-d214bee7106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      name date_of_birth    age\n",
      "0  alberto     17/05/2002  18.5\n",
      "1     gino     16/02/1999  21.2\n",
      "2     ryan     25/09/1998  22.5\n",
      "3    Eesha     11/05/2002  22.0\n",
      "4     syed     15/09/1997  23.0\n",
      "\n",
      "After capitalizing name column:\n",
      "      name date_of_birth    age\n",
      "0  Alberto     17/05/2002  18.5\n",
      "1     Gino     16/02/1999  21.2\n",
      "2     Ryan     25/09/1998  22.5\n",
      "3    Eesha     11/05/2002  22.0\n",
      "4     Syed     15/09/1997  23.0\n",
      "      name date_of_birth    age\n",
      "0  ALBERTO     17/05/2002  18.5\n",
      "1     GINO     16/02/1999  21.2\n",
      "2     RYAN     25/09/1998  22.5\n",
      "3    EESHA     11/05/2002  22.0\n",
      "4     SYED     15/09/1997  23.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'name': ['alberto','gino','ryan', 'Eesha', 'syed'],\n",
    "    'date_of_birth ': ['17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [18.5, 21.2, 22.5, 22, 23]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nAfter capitalizing name column:\")\n",
    "df['name'] = list(map(lambda x: x.capitalize(), df['name']))\n",
    "print(df)\n",
    "df['name'] = df['name'].str.upper()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8d9a2-8dc4-41af-8165-1ebe2ef95952",
   "metadata": {},
   "source": [
    "5. Write a Pandas program to count of occurrence of a specified substring in a DataFrame column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "495c8a3e-f581-4715-8be1-220d37b226a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  name_code date_of_birth    age\n",
      "0      c001     12/05/2002  18.5\n",
      "1      c002     16/02/1999  21.2\n",
      "2      c022     25/09/1998  22.5\n",
      "3     c2002     12/02/2022  22.0\n",
      "4     c2222     15/09/1997  23.0\n",
      "\n",
      "Count occurrence of 2 in name_code:\n",
      "  name_code date_of_birth    age  count\n",
      "0      c001     12/05/2002  18.5      0\n",
      "1      c002     16/02/1999  21.2      1\n",
      "2      c022     25/09/1998  22.5      2\n",
      "3     c2002     12/02/2022  22.0      2\n",
      "4     c2222     15/09/1997  23.0      4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'name_code': ['c001','c002','c022', 'c2002', 'c2222'],\n",
    "    'date_of_birth ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
    "    'age': [18.5, 21.2, 22.5, 22, 23]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nCount occurrence of 2 in name_code:\")\n",
    "df['count'] = list(map(lambda x: x.count(\"2\"), df['name_code']))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a4ee3b-ac66-4934-88b8-6aeffc2c4fd9",
   "metadata": {},
   "source": [
    "6. Write a Pandas program to find the index of a given substring of a DataFrame column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f21c5f47-6f7d-4b46-8779-0ed89d165945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  name_code date_of_birth  age\n",
      "0      c001     12/05/2002  18\n",
      "1      c002     16/02/1999  21\n",
      "2      c022     25/09/1998  22\n",
      "3     c2002     12/02/2022  22\n",
      "4     c2222     15/09/1997  23\n",
      "\n",
      "Count occurrence of 22 in age column:\n",
      "  name_code date_of_birth  age  Index\n",
      "0      c001     12/05/2002  18     -1\n",
      "1      c002     16/02/1999  21     -1\n",
      "2      c022     25/09/1998  22      0\n",
      "3     c2002     12/02/2022  22      0\n",
      "4     c2222     15/09/1997  23     -1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'name_code': ['c001','c002','c022', 'c2002', 'c2222'],\n",
    "    'date_of_birth ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
    "    'age': ['18', '21', '22', '22', '23']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nCount occurrence of 22 in age column:\")\n",
    "df['Index'] = list(map(lambda x: x.find('22'), df['age']))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706ab07-1549-40fb-b3ac-68bc1d454600",
   "metadata": {},
   "source": [
    "7. Write a Pandas program to check whether alpha numeric values present in a given column of a DataFrame.\n",
    "Note: isalnum() function returns True if all characters in the string are alphanumeric and there is at least one character, False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "581e9dd1-a30d-45db-a94e-4fa166186d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      name_code date_of_birth    age\n",
      "0       Company     12/05/2002  18.5\n",
      "1  Company a001     16/02/1999  21.2\n",
      "2   Company 123     25/09/1998  22.5\n",
      "3          1234     12/02/2022  22.0\n",
      "4    Company 12     15/09/1997  23.0\n",
      "\n",
      "Whether all characters in the string are alphanumeric?\n",
      "      name_code date_of_birth    age  name_code_is_alphanumeric\n",
      "0       Company     12/05/2002  18.5                       True\n",
      "1  Company a001     16/02/1999  21.2                      False\n",
      "2   Company 123     25/09/1998  22.5                      False\n",
      "3          1234     12/02/2022  22.0                       True\n",
      "4    Company 12     15/09/1997  23.0                      False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'name_code': ['Company','Company a001','Company 123', '1234', 'Company 12'],\n",
    "    'date_of_birth ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
    "    'age': [18.5, 21.2, 22.5, 22, 23]\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nWhether all characters in the string are alphanumeric?\")\n",
    "df['name_code_is_alphanumeric'] = list(map(lambda x: x.isalnum(), df['name_code']))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3f6d01-2c91-42dd-b48d-dbea9555a4a8",
   "metadata": {},
   "source": [
    "8. Write a Pandas program to check whether alphabetic values present in a given column of a DataFrame.\n",
    "Note: isalpha() returns True if all characters in the string are alphabetic and there is at least one character, False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abd8a769-6eb8-4a92-a388-ed348893063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   company_code date_of_sale   sale_amount\n",
      "0       Company    12/05/2002      12348.5\n",
      "1  Company a001    16/02/1999     233331.2\n",
      "2   Company 123    25/09/1998         22.5\n",
      "3          abcd    12/02/2022    2566552.0\n",
      "4    Company 12    15/09/1997         23.0\n",
      "\n",
      "Whether Alphabetic values present in company_code column?\n",
      "   company_code date_of_sale   sale_amount  company_code_is_alpha\n",
      "0       Company    12/05/2002      12348.5                   True\n",
      "1  Company a001    16/02/1999     233331.2                  False\n",
      "2   Company 123    25/09/1998         22.5                  False\n",
      "3          abcd    12/02/2022    2566552.0                   True\n",
      "4    Company 12    15/09/1997         23.0                  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'company_code': ['Company','Company a001','Company 123', 'abcd', 'Company 12'],\n",
    "    'date_of_sale ': ['12/05/2002','16/02/1999','25/09/1998','12/02/2022','15/09/1997'],\n",
    "    'sale_amount': [12348.5, 233331.2, 22.5, 2566552.0, 23.0]})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nWhether Alphabetic values present in company_code column?\")\n",
    "df['company_code_is_alpha'] = list(map(lambda x: x.isalpha(), df['company_code']))\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1da30b-93d6-44d8-b4b5-50cb4064549f",
   "metadata": {},
   "source": [
    "# Pandas Joining and Merging\n",
    "\n",
    "1. Write a Pandas program to join the two given dataframes along rows and assign all data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b9ed7aa-dbe8-47b1-baea-3d08c7cd8c90",
   "metadata": {},
   "source": [
    "Test Data:\n",
    "\n",
    "student_data1:\n",
    "  student_id              name  marks\n",
    "0         S1  Danniella Fenton    200\n",
    "1         S2      Ryder Storey    210\n",
    "2         S3      Bryce Jensen    190\n",
    "3         S4         Ed Bernal    222\n",
    "4         S5       Kwame Morin    199\n",
    "\n",
    "student_data2:\n",
    "  student_id              name  marks\n",
    "0         S4  Scarlette Fisher    201\n",
    "1         S5  Carla Williamson    200\n",
    "2         S6       Dante Morse    198\n",
    "3         S7    Kaiser William    219\n",
    "4         S8   Madeeha Preston    201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2adc88b0-fa48-47a3-8de5-9be9f14d6232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Joining the two dataframes along rows:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "\n",
    "print(student_data2)\n",
    "\n",
    "print(\"\\nJoining the two dataframes along rows:\")\n",
    "result_data = pd.concat([student_data1, student_data2])\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18df6e84-ccbd-4ff3-941d-ac4295ba3fde",
   "metadata": {},
   "source": [
    "2. Write a Pandas program to join the two given dataframes along columns and assign all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c128ebe-95c0-460c-a2dc-7b8ca5803a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Join the said two dataframes along columns:\n",
      "  student_id              name  marks student_id              name  marks\n",
      "0         S1  Danniella Fenton    200         S4  Scarlette Fisher    201\n",
      "1         S2      Ryder Storey    210         S5  Carla Williamson    200\n",
      "2         S3      Bryce Jensen    190         S6       Dante Morse    198\n",
      "3         S4         Ed Bernal    222         S7    Kaiser William    219\n",
      "4         S5       Kwame Morin    199         S8   Madeeha Preston    201\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "\n",
    "print(student_data2)\n",
    "\n",
    "print(\"\\nJoin the said two dataframes along columns:\")\n",
    "result_data = pd.concat([student_data1, student_data2], axis = 1)\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27101a-84cd-446e-b541-40489afd0f3f",
   "metadata": {},
   "source": [
    "3. Write a Pandas program to append rows to an existing DataFrame and display the combined data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a835b39f-d8ec-4629-9ef2-90c2538f7584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name  Age           City\n",
      "0  John   28       New York\n",
      "1  Jane   22    Los Angeles\n",
      "2   Tom   25        Chicago\n",
      "3  Mike   30  San Francisco\n",
      "4  Anna   26         Boston\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = {'Name': ['John', 'Jane', 'Tom'],\n",
    "         'Age': [28, 22, 25],\n",
    "         'City': ['New York', 'Los Angeles', 'Chicago']}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {'Name': ['Mike', 'Anna'],\n",
    "         'Age': [30, 26],\n",
    "         'City': ['San Francisco', 'Boston']}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "df_combined = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "print(df_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a721ef-9672-4696-8742-2190992f5422",
   "metadata": {},
   "source": [
    "4. Write a Pandas program to join the two given dataframes along rows and merge with another dataframe along the common column id."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d26297d-eaaa-4145-bf52-070a554c7ba9",
   "metadata": {},
   "source": [
    "Test Data:\n",
    "\n",
    "student_data1:\n",
    "  student_id              name  marks\n",
    "0         S1  Danniella Fenton    200\n",
    "1         S2      Ryder Storey    210\n",
    "2         S3      Bryce Jensen    190\n",
    "3         S4         Ed Bernal    222\n",
    "4         S5       Kwame Morin    199\n",
    "\n",
    "student_data2:\n",
    "  student_id              name  marks\n",
    "0         S4  Scarlette Fisher    201\n",
    "1         S5  Carla Williamson    200\n",
    "2         S6       Dante Morse    198\n",
    "3         S7    Kaiser William    219\n",
    "4         S8   Madeeha Preston    201\n",
    "exam_data:\n",
    "   student_id  exam_id\n",
    "0          S1       23\n",
    "1          S2       45\n",
    "2          S3       12\n",
    "3          S4       67\n",
    "4          S5       21\n",
    "5          S7       55\n",
    "6          S8       33\n",
    "7          S9       14\n",
    "8         S10       56\n",
    "9         S11       83\n",
    "10        S12       88\n",
    "11        S13       12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "28380a9a-ec9b-41b3-a635-a98a0572567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "   student_id  exam_id\n",
      "0          S1       23\n",
      "1          S2       45\n",
      "2          S3       12\n",
      "3          S4       67\n",
      "4          S5       21\n",
      "5          S7       55\n",
      "6          S8       33\n",
      "7          S9       14\n",
      "8         S10       56\n",
      "9         S11       83\n",
      "10        S12       88\n",
      "11        S13       12\n",
      "\n",
      "Join first two said dataframes along rows:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Now join the said result_data and df_exam_data along student_id:\n",
      "  student_id              name  marks  exam_id\n",
      "0         S1  Danniella Fenton    200       23\n",
      "1         S2      Ryder Storey    210       45\n",
      "2         S3      Bryce Jensen    190       12\n",
      "3         S4         Ed Bernal    222       67\n",
      "4         S5       Kwame Morin    199       21\n",
      "5         S4  Scarlette Fisher    201       67\n",
      "6         S5  Carla Williamson    200       21\n",
      "7         S7    Kaiser William    219       55\n",
      "8         S8   Madeeha Preston    201       33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "exam_data = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13'],\n",
    "        'exam_id': [23, 45, 12, 67, 21, 55, 33, 14, 56, 83, 88, 12]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(student_data2)\n",
    "print(exam_data)\n",
    "\n",
    "print(\"\\nJoin first two said dataframes along rows:\")\n",
    "result_data = pd.concat([student_data1, student_data2])\n",
    "print(result_data)\n",
    "\n",
    "print(\"\\nNow join the said result_data and df_exam_data along student_id:\")\n",
    "final_merged_data = pd.merge(result_data, exam_data, on='student_id')\n",
    "print(final_merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff56100f-b794-4ea3-8453-27223babfad1",
   "metadata": {},
   "source": [
    "5. Write a Pandas program to join the two dataframes with matching records from both sides where available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6bdd414-c0a7-4b72-9129-72a81e386ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "Merged data (outer join):\n",
      "  student_id            name_x  marks_x            name_y  marks_y\n",
      "0         S1  Danniella Fenton    200.0               NaN      NaN\n",
      "1         S2      Ryder Storey    210.0               NaN      NaN\n",
      "2         S3      Bryce Jensen    190.0               NaN      NaN\n",
      "3         S4         Ed Bernal    222.0  Scarlette Fisher    201.0\n",
      "4         S5       Kwame Morin    199.0  Carla Williamson    200.0\n",
      "5         S6               NaN      NaN       Dante Morse    198.0\n",
      "6         S7               NaN      NaN    Kaiser William    219.0\n",
      "7         S8               NaN      NaN   Madeeha Preston    201.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "student_data1 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "         'name': ['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'], \n",
    "        'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame({\n",
    "        'student_id': ['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "        'name': ['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'], \n",
    "        'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(student_data2)\n",
    "\n",
    "merged_data = pd.merge(student_data1, student_data2, on='student_id', how='outer')\n",
    "print(\"Merged data (outer join):\")\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba06d884-e1ab-4308-a664-f8fda3f34fb1",
   "metadata": {},
   "source": [
    "6. Write a Pandas program to join (left join) the two dataframes using keys from left dataframe only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7eadedaf-f620-4c25-b9b8-39a257e2d72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  key1 key2   P   Q\n",
      "0   K0   K0  P0  Q0\n",
      "1   K0   K1  P1  Q1\n",
      "2   K1   K0  P2  Q2\n",
      "3   K2   K1  P3  Q3\n",
      "--------------------\n",
      "  key1 key2   R   S\n",
      "0   K0   K0  R0  S0\n",
      "1   K1   K0  R1  S1\n",
      "2   K1   K0  R2  S2\n",
      "3   K2   K0  R3  S3\n",
      "\n",
      "Merged Data (keys from data1):\n",
      "  key1 key2   P   Q    R    S\n",
      "0   K0   K0  P0  Q0   R0   S0\n",
      "1   K0   K1  P1  Q1  NaN  NaN\n",
      "2   K1   K0  P2  Q2   R1   S1\n",
      "3   K1   K0  P2  Q2   R2   S2\n",
      "4   K2   K1  P3  Q3  NaN  NaN\n",
      "\n",
      "Merged Data (keys from data2):\n",
      "  key1 key2   R   S    P    Q\n",
      "0   K0   K0  R0  S0   P0   Q0\n",
      "1   K1   K0  R1  S1   P2   Q2\n",
      "2   K1   K0  R2  S2   P2   Q2\n",
      "3   K2   K0  R3  S3  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
    "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']}) \n",
    "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
    "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
    "print(\"Original DataFrames:\")\n",
    "print(data1)\n",
    "print(\"--------------------\")\n",
    "print(data2)\n",
    "print(\"\\nMerged Data (keys from data1):\")\n",
    "merged_data = pd.merge(data1, data2, how='left', on=['key1', 'key2'])\n",
    "print(merged_data)\n",
    "print(\"\\nMerged Data (keys from data2):\")\n",
    "merged_data = pd.merge(data2, data1, how='left', on=['key1', 'key2'])\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e15d22-9b71-40d5-a8a3-f739377ecf00",
   "metadata": {},
   "source": [
    "7. Write a Pandas program to join two dataframes using keys from right dataframe only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "875daf00-bf43-42e7-99d2-9ded6caa4343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  key1 key2   P   Q\n",
      "0   K0   K0  P0  Q0\n",
      "1   K0   K1  P1  Q1\n",
      "2   K1   K0  P2  Q2\n",
      "3   K2   K1  P3  Q3\n",
      "--------------------\n",
      "  key1 key2   R   S\n",
      "0   K0   K0  R0  S0\n",
      "1   K1   K0  R1  S1\n",
      "2   K1   K0  R2  S2\n",
      "3   K2   K0  R3  S3\n",
      "\n",
      "Merged Data (keys from data1):\n",
      "  key1 key2    P    Q   R   S\n",
      "0   K0   K0   P0   Q0  R0  S0\n",
      "1   K1   K0   P2   Q2  R1  S1\n",
      "2   K1   K0   P2   Q2  R2  S2\n",
      "3   K2   K0  NaN  NaN  R3  S3\n",
      "\n",
      "Merged Data (keys from data2):\n",
      "  key1 key2    R    S   P   Q\n",
      "0   K0   K0   R0   S0  P0  Q0\n",
      "1   K0   K1  NaN  NaN  P1  Q1\n",
      "2   K1   K0   R1   S1  P2  Q2\n",
      "3   K1   K0   R2   S2  P2  Q2\n",
      "4   K2   K1  NaN  NaN  P3  Q3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
    "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']}) \n",
    "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
    "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
    "print(\"Original DataFrames:\")\n",
    "print(data1)\n",
    "print(\"--------------------\")\n",
    "print(data2)\n",
    "print(\"\\nMerged Data (keys from data1):\")\n",
    "merged_data = pd.merge(data1, data2, how='right', on=['key1', 'key2'])\n",
    "print(merged_data)\n",
    "print(\"\\nMerged Data (keys from data2):\")\n",
    "merged_data = pd.merge(data2, data1, how='right', on=['key1', 'key2'])\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09fc00f-044b-4c8c-ac46-29dca54ae98d",
   "metadata": {},
   "source": [
    "8. Write a Pandas program to merge two given datasets using multiple join keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "35040f73-a2fe-431c-a43b-283e31273e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  key1 key2   P   Q\n",
      "0   K0   K0  P0  Q0\n",
      "1   K0   K1  P1  Q1\n",
      "2   K1   K0  P2  Q2\n",
      "3   K2   K1  P3  Q3\n",
      "--------------------\n",
      "  key1 key2   R   S\n",
      "0   K0   K0  R0  S0\n",
      "1   K1   K0  R1  S1\n",
      "2   K1   K0  R2  S2\n",
      "3   K2   K0  R3  S3\n",
      "\n",
      "Merged Data :\n",
      "  key1 key2   P   Q   R   S\n",
      "0   K0   K0  P0  Q0  R0  S0\n",
      "1   K1   K0  P2  Q2  R1  S1\n",
      "2   K1   K0  P2  Q2  R2  S2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
    "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']}) \n",
    "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
    "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
    "print(\"Original DataFrames:\")\n",
    "print(data1)\n",
    "print(\"--------------------\")\n",
    "print(data2)\n",
    "print(\"\\nMerged Data :\")\n",
    "merged_data = pd.merge(data1, data2, on=['key1', 'key2'])\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b1760-d047-4ccd-87e3-9491ec7e630a",
   "metadata": {},
   "source": [
    "9. Write a Pandas program to create a new DataFrame based on existing series, using specified argument and override the existing columns names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58822efc-01ae-498b-be80-6763ae39eb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column1  column2  column3\n",
      "0        0        0        0\n",
      "1        1        1        1\n",
      "2        2        2        4\n",
      "3        3        3        5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "s1 = pd.Series([0, 1, 2, 3], name='col1')\n",
    "s2 = pd.Series([0, 1, 2, 3])\n",
    "s3 = pd.Series([0, 1, 4, 5], name='col3')\n",
    "df = pd.concat([s1, s2, s3], axis=1, keys=['column1', 'column2', 'column3'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb8ee5-5a74-433a-9629-e06eb8ff3646",
   "metadata": {},
   "source": [
    "10. Write a Pandas program to create a combination from two dataframes where a column id combination appears more than once in both dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b076ba1-5d55-4108-b9bd-91b87700abaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  key1 key2   P   Q\n",
      "0   K0   K0  P0  Q0\n",
      "1   K0   K1  P1  Q1\n",
      "2   K1   K0  P2  Q2\n",
      "3   K2   K1  P3  Q3\n",
      "--------------------\n",
      "  key1 key2   R   S\n",
      "0   K0   K0  R0  S0\n",
      "1   K1   K0  R1  S1\n",
      "2   K1   K0  R2  S2\n",
      "3   K2   K0  R3  S3\n",
      "\n",
      "Merged Data (many-to-many join case):\n",
      "  key1 key2_x   P   Q key2_y   R   S\n",
      "0   K0     K0  P0  Q0     K0  R0  S0\n",
      "1   K0     K1  P1  Q1     K0  R0  S0\n",
      "2   K1     K0  P2  Q2     K0  R1  S1\n",
      "3   K1     K0  P2  Q2     K0  R2  S2\n",
      "4   K2     K1  P3  Q3     K0  R3  S3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n",
    "                     'key2': ['K0', 'K1', 'K0', 'K1'],\n",
    "                     'P': ['P0', 'P1', 'P2', 'P3'],\n",
    "                     'Q': ['Q0', 'Q1', 'Q2', 'Q3']}) \n",
    "data2 = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n",
    "                      'key2': ['K0', 'K0', 'K0', 'K0'],\n",
    "                      'R': ['R0', 'R1', 'R2', 'R3'],\n",
    "                      'S': ['S0', 'S1', 'S2', 'S3']})\n",
    "print(\"Original DataFrames:\")\n",
    "print(data1)\n",
    "print(\"--------------------\")\n",
    "print(data2)\n",
    "print(\"\\nMerged Data (many-to-many join case):\")\n",
    "result = pd.merge(data1, data2, on='key1')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8cb80-b5f7-475b-bcc6-749e47fbddb6",
   "metadata": {},
   "source": [
    "# Pandas Grouping and Aggregating\n",
    "\n",
    "1. Write a Pandas program to split the following dataframe into groups based on school code. Also check the type of GroupBy object.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "687774ac-fb4b-4b7e-9009-fafed3be9ad5",
   "metadata": {},
   "source": [
    "Test Data:\n",
    "\n",
    "   school class            name date_Of_Birth   age  height  weight  address\n",
    "S1   s001     V  Alberto Franco     15/05/2002   12    173      35  street1\n",
    "S2   s002     V    Gino Mcneill     17/05/2002   12    192      32  street2\n",
    "S3   s003    VI     Ryan Parkes     16/02/1999   13    186      33  street3\n",
    "S4   s001    VI    Eesha Hinton     25/09/1998   13    167      30  street1\n",
    "S5   s002     V    Gino Mcneill     11/05/2002   14    151      31  street2\n",
    "S6   s004    VI    David Parkes     15/09/1997   12    159      32  street4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c1cb71a9-a596-4266-8cba-e13d2f6fdda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code wise:\n",
      "\n",
      " Group:\n",
      "('s001',)\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "\n",
      " Group:\n",
      "('s002',)\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "\n",
      " Group:\n",
      "('s003',)\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "\n",
      " Group:\n",
      "('s004',)\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n",
      "\n",
      " Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "\n",
    "result = student_data.groupby(['school_code'])\n",
    "\n",
    "for name, group in result:\n",
    "    print(\"\\n Group:\")\n",
    "    print(name)\n",
    "    print(group)\n",
    "    \n",
    "print(\"\\n Type of the object:\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84efd601-2c53-4aba-812f-efaafccf59f1",
   "metadata": {},
   "source": [
    "2. Write a Pandas program to split the following dataframe by school code and get mean, min, and max value of age for each school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6732e74a-d4ba-4c07-9fcb-dbfdd5436a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Mean, min, and max value of age for each value of the school:\n",
      "              age        \n",
      "             mean min max\n",
      "school_code              \n",
      "s001         12.5  12  13\n",
      "s002         13.0  12  14\n",
      "s003         13.0  13  13\n",
      "s004         12.0  12  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "\n",
    "print('\\nMean, min, and max value of age for each value of the school:')\n",
    "grouped_single = student_data.groupby('school_code').agg({'age': ['mean', 'min', 'max']})\n",
    "print(grouped_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78e6e5-38b1-4058-a1fc-980f17c9c1be",
   "metadata": {},
   "source": [
    "3. Write a Pandas program to split the following given dataframe into groups based on school code and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "887b6ec1-8e5d-4924-b7c9-10abb738fb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code wise:\n",
      "\n",
      " Group:\n",
      "('s001', 'V')\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "\n",
      " Group:\n",
      "('s001', 'VI')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S4        s001    VI  Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S4  street1  \n",
      "\n",
      " Group:\n",
      "('s002', 'V')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "\n",
      " Group:\n",
      "('s003', 'VI')\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "\n",
      " Group:\n",
      "('s004', 'VI')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "\n",
    "result = student_data.groupby(['school_code', 'class'])\n",
    "\n",
    "for name, group in result:\n",
    "    print(\"\\n Group:\")\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3b755-613b-4a70-b6c1-e8f37dffbae5",
   "metadata": {},
   "source": [
    "4. Write a Pandas program to split the following given dataframe into groups based on school code and cast grouping as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a21af06d-feab-49c1-aa7b-acf233c71923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Cast grouping as a list:\n",
      "[(('s001',),    school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  ), (('s002',),    school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  ), (('s003',),    school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3), (('s004',),    school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  )]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nCast grouping as a list:')\n",
    "result = student_data.groupby(['school_code'])\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd9f82-3ac2-4dfe-bed3-9fe2af47b107",
   "metadata": {},
   "source": [
    "5. Write a Pandas program to split the following given dataframe into groups based on single column and multiple columns. Find the size of the grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ea4c351-b191-495d-b1ec-26410a53964d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code wise:\n",
      "Size of the grouped data - single column\n",
      "school_code\n",
      "s001    2\n",
      "s002    2\n",
      "s003    1\n",
      "s004    1\n",
      "dtype: int64\n",
      "\n",
      "Split the said data on school_code and class wise:\n",
      "Size of the grouped data - multiple columns:\n",
      "school_code  class\n",
      "s001         V        1\n",
      "             VI       1\n",
      "s002         V        2\n",
      "s003         VI       1\n",
      "s004         VI       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "grouped_single = student_data.groupby(['school_code'])\n",
    "print(\"Size of the grouped data - single column\")\n",
    "print(grouped_single.size())\n",
    "print('\\nSplit the said data on school_code and class wise:')\n",
    "\n",
    "grouped_mul = student_data.groupby(['school_code', 'class'])\n",
    "print(\"Size of the grouped data - multiple columns:\")\n",
    "print(grouped_mul.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec038ba6-61d9-4bbf-b15e-4d1d4b2a1953",
   "metadata": {},
   "source": [
    "6. Write a Pandas program to split the following given dataframe into groups based on school code and call a specific group with the name of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c822e360-17a4-4b09-a9de-25b162953aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code wise:\n",
      "Call school code 's001':\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "\n",
      "Call school code 's004':\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7544\\681831932.py:19: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  print(grouped.get_group('s001'))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7544\\681831932.py:21: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  print(grouped.get_group('s004'))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "grouped = student_data.groupby(['school_code'])\n",
    "print(\"Call school code 's001':\")\n",
    "print(grouped.get_group('s001'))\n",
    "print(\"\\nCall school code 's004':\")\n",
    "print(grouped.get_group('s004'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a64ba65-8714-4e74-96c0-fbbd52ee274b",
   "metadata": {},
   "source": [
    "7. Write a Pandas program to split a dataset, group by one column and get mean, min, and max values by group. Using the following dataset find the mean, min, and max values of purchase amount (purch_amt) group by customer id (customer_id)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ad07d1c-8e74-48e9-b685-e0ea939aa715",
   "metadata": {},
   "source": [
    "Test Data:\n",
    "\n",
    "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
    "0    70001     150.50  2012-10-05         3005         5002\n",
    "1    70009     270.65  2012-09-10         3001         5005\n",
    "2    70002      65.26  2012-10-05         3002         5001\n",
    "3    70004     110.50  2012-08-17         3009         5003\n",
    "4    70007     948.50  2012-09-10         3005         5002\n",
    "5    70005    2400.60  2012-07-27         3007         5001\n",
    "6    70008    5760.00  2012-09-10         3002         5001\n",
    "7    70010    1983.43  2012-10-10         3004         5006\n",
    "8    70003    2480.40  2012-10-10         3009         5003\n",
    "9    70012     250.45  2012-06-27         3008         5002\n",
    "10   70011      75.29  2012-08-17         3003         5007\n",
    "11   70013    3045.60  2012-04-25         3002         5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b92e02a-760b-46e7-b335-86f6cc496a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0    70001     150.50  2012-10-05         3005         5002\n",
      "1    70009     270.65  2012-09-10         3001         5005\n",
      "2    70002      65.26  2012-10-05         3002         5001\n",
      "3    70004     110.50  2012-08-17         3009         5003\n",
      "4    70007     948.50  2012-09-10         3005         5002\n",
      "5    70005    2400.60  2012-07-27         3007         5001\n",
      "6    70008    5760.00  2012-09-10         3002         5001\n",
      "7    70010    1983.43  2012-10-10         3004         5006\n",
      "8    70003    2480.40  2012-10-10         3009         5003\n",
      "9    70012     250.45  2012-06-27         3008         5002\n",
      "10   70011      75.29  2012-08-17         3003         5007\n",
      "11   70013    3045.60  2012-04-25         3002         5001\n",
      "\n",
      "Mean, min, and max values of purchase amount (purch_amt) group by customer id  (customer_id).\n",
      "               purch_amt                  \n",
      "                    mean      min      max\n",
      "customer_id                               \n",
      "3001          270.650000   270.65   270.65\n",
      "3002         2956.953333    65.26  5760.00\n",
      "3003           75.290000    75.29    75.29\n",
      "3004         1983.430000  1983.43  1983.43\n",
      "3005          549.500000   150.50   948.50\n",
      "3007         2400.600000  2400.60  2400.60\n",
      "3008          250.450000   250.45   250.45\n",
      "3009         1295.450000   110.50  2480.40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "orders_data = pd.DataFrame({\n",
    "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
    "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(orders_data)\n",
    "result = orders_data.groupby('customer_id').agg({'purch_amt': ['mean', 'min', 'max']})\n",
    "print(\"\\nMean, min, and max values of purchase amount (purch_amt) group by customer id  (customer_id).\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baacd64-6b97-4723-b12e-73c51837b695",
   "metadata": {},
   "source": [
    "8. Write a Pandas program to split a dataset to group by two columns and count by each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "18d1eedb-0e16-4c50-bdb5-457a9f66b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0    70001     150.50  2012-10-05         3005         5002\n",
      "1    70009     270.65  2012-09-10         3001         5005\n",
      "2    70002      65.26  2012-10-05         3002         5001\n",
      "3    70004     110.50  2012-08-17         3009         5003\n",
      "4    70007     948.50  2012-09-10         3005         5002\n",
      "5    70005    2400.60  2012-07-27         3007         5001\n",
      "6    70008    5760.00  2012-09-10         3002         5001\n",
      "7    70010    1983.43  2012-10-10         3004         5006\n",
      "8    70003    2480.40  2012-10-10         3009         5003\n",
      "9    70012     250.45  2012-06-27         3008         5002\n",
      "10   70011      75.29  2012-08-17         3003         5007\n",
      "11   70013    3045.60  2012-04-25         3002         5001\n",
      "\n",
      "Group by two columns and count by each row:\n",
      "                         0\n",
      "salesman_id customer_id   \n",
      "5001        3002         3\n",
      "            3007         1\n",
      "5002        3005         2\n",
      "            3008         1\n",
      "5003        3009         2\n",
      "5005        3001         1\n",
      "5006        3004         1\n",
      "5007        3003         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "orders_data = pd.DataFrame({\n",
    "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3005,3001,3002,3009,3005,3007,3002,3004,3009,3008,3003,3002],\n",
    "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(orders_data)\n",
    "print(\"\\nGroup by two columns and count by each row:\")\n",
    "result = orders_data.groupby(['salesman_id','customer_id']).size().reset_index().groupby(['salesman_id','customer_id'])[[0]].max()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bd264-aa5f-4ced-b9bd-fbf2708df504",
   "metadata": {},
   "source": [
    "9. Write a Pandas program to split a dataset to group by two columns and then sort the aggregated results within the groups.\n",
    "In the following dataset group on 'customer_id', 'salesman_id' and then sort sum of purch_amt within the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c8e65793-dd2a-48ea-ab37-37300c67b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0    70001     150.50  2012-10-05         3001         5002\n",
      "1    70009     270.65  2012-09-10         3001         5005\n",
      "2    70002      65.26  2012-10-05         3005         5001\n",
      "3    70004     110.50  2012-08-17         3001         5003\n",
      "4    70007     948.50  2012-09-10         3005         5002\n",
      "5    70005    2400.60  2012-07-27         3001         5001\n",
      "6    70008    5760.00  2012-09-10         3005         5001\n",
      "7    70010    1983.43  2012-10-10         3001         5006\n",
      "8    70003    2480.40  2012-10-10         3005         5003\n",
      "9    70012     250.45  2012-06-27         3001         5002\n",
      "10   70011      75.29  2012-08-17         3005         5007\n",
      "11   70013    3045.60  2012-04-25         3005         5001\n",
      "\n",
      "Group on 'customer_id', 'salesman_id' and then sort sum of purch_amt within the groups:\n",
      "customer_id  salesman_id\n",
      "3001         5001           2400.60\n",
      "             5006           1983.43\n",
      "             5002            400.95\n",
      "             5005            270.65\n",
      "             5003            110.50\n",
      "3005         5001           8870.86\n",
      "             5003           2480.40\n",
      "             5002            948.50\n",
      "             5007             75.29\n",
      "Name: purch_amt, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7544\\3231003253.py:13: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  df_agg = df.groupby(['customer_id','salesman_id']).agg({'purch_amt':sum})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
    "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
    "\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "df_agg = df.groupby(['customer_id','salesman_id']).agg({'purch_amt':sum})\n",
    "result = df_agg['purch_amt'].groupby(level=0, group_keys=False)\n",
    "print(\"\\nGroup on 'customer_id', 'salesman_id' and then sort sum of purch_amt within the groups:\")\n",
    "print(result.nlargest())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7d620-d593-451e-807e-37dc743dfe99",
   "metadata": {},
   "source": [
    "10. Write a Pandas program to split the following dataframe into groups based on customer id and create a list of order date for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "84ff3aad-e79c-4f44-8898-e73032438ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0    70001     150.50  2012-10-05         3001         5002\n",
      "1    70009     270.65  2012-09-10         3001         5005\n",
      "2    70002      65.26  2012-10-05         3005         5001\n",
      "3    70004     110.50  2012-08-17         3001         5003\n",
      "4    70007     948.50  2012-09-10         3005         5002\n",
      "5    70005    2400.60  2012-07-27         3001         5001\n",
      "6    70008    5760.00  2012-09-10         3005         5001\n",
      "7    70010    1983.43  2012-10-10         3001         5006\n",
      "8    70003    2480.40  2012-10-10         3005         5003\n",
      "9    70012     250.45  2012-06-27         3001         5002\n",
      "10   70011      75.29  2012-08-17         3005         5007\n",
      "11   70013    3045.60  2012-04-25         3005         5001\n",
      "\n",
      "Group on 'customer_id' and display the list of order dates in group wise:\n",
      "customer_id\n",
      "3001    [2012-10-05, 2012-09-10, 2012-08-17, 2012-07-2...\n",
      "3005    [2012-10-05, 2012-09-10, 2012-09-10, 2012-10-1...\n",
      "Name: ord_date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10','2012-10-05','2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
    "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "result = df.groupby('customer_id')['ord_date'].apply(list)\n",
    "print(\"\\nGroup on 'customer_id' and display the list of order dates in group wise:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141c9fe-a2af-475d-9ce5-4d2c8b0c9cea",
   "metadata": {},
   "source": [
    "11. Write a Pandas program to split the following dataframe into groups and calculate monthly purchase amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5099dfca-472f-4f6e-aaa5-295f8a1c2102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0    70001     150.50  05-10-2012         3001         5002\n",
      "1    70009     270.65  09-10-2012         3001         5005\n",
      "2    70002      65.26  05-10-2012         3005         5001\n",
      "3    70004     110.50  08-17-2012         3001         5003\n",
      "4    70007     948.50  10-09-2012         3005         5002\n",
      "5    70005    2400.60  07-27-2012         3001         5001\n",
      "6    70008    5760.00  10-09-2012         3005         5001\n",
      "7    70010    1983.43  10-10-2012         3001         5006\n",
      "8    70003    2480.40  10-10-2012         3005         5003\n",
      "9    70012     250.45  06-17-2012         3001         5002\n",
      "10   70011      75.29  07-08-2012         3005         5007\n",
      "11   70013    3045.60  04-25-2012         3005         5001\n",
      "\n",
      "Month wise purchase amount:\n",
      "            purch_amt\n",
      "ord_date             \n",
      "2012-04-30    3045.60\n",
      "2012-05-31     215.76\n",
      "2012-06-30     250.45\n",
      "2012-07-31    2475.89\n",
      "2012-08-31     110.50\n",
      "2012-09-30     270.65\n",
      "2012-10-31   11172.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7544\\702042559.py:15: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  result = df.set_index('ord_date').groupby(pd.Grouper(freq='M')).agg({'purch_amt':sum})\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_7544\\702042559.py:15: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  result = df.set_index('ord_date').groupby(pd.Grouper(freq='M')).agg({'purch_amt':sum})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,70009,70002,70004,70007,70005,70008,70010,70003,70012,70011,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['05-10-2012','09-10-2012','05-10-2012','08-17-2012','10-09-2012','07-27-2012','10-09-2012','10-10-2012','10-10-2012','06-17-2012','07-08-2012','04-25-2012'],\n",
    "'customer_id':[3001,3001,3005,3001,3005,3001,3005,3001,3005,3001,3005,3005],\n",
    "'salesman_id': [5002,5005,5001,5003,5002,5001,5001,5006,5003,5002,5007,5001]})\n",
    "\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "df['ord_date']= pd.to_datetime(df['ord_date']) \n",
    "print(\"\\nMonth wise purchase amount:\")\n",
    "result = df.set_index('ord_date').groupby(pd.Grouper(freq='M')).agg({'purch_amt':sum})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb679a-6454-4870-94cd-e503f01aa1f0",
   "metadata": {},
   "source": [
    "# Pandas Excel\n",
    "\n",
    "1. Write a Pandas program to import excel data (coalpublic2013.xlsx ) into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fd743284-79eb-4569-aeca-7d348d3d2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of     Year  MSHA ID                       Mine_Name  Production  Labor_Hours\n",
      "0   2013   103381            Tacoa Highwall Miner       56004        22392\n",
      "1   2013   103404                Reid School Mine       28807        28447\n",
      "2   2013   100759  North River #1 Underground Min     1440115       474784\n",
      "3   2013   103246                      Bear Creek       87587        29193\n",
      "4   2013   103451                     Knight Mine      147499        46393\n",
      "5   2013   103433              Crane Central Mine       69339        47195\n",
      "6   2013   100329                    Concord Mine           0       144002\n",
      "7   2013   100851                  Oak Grove Mine     2269014      1001809\n",
      "8   2013   102901                Shoal Creek Mine           0        12396\n",
      "9   2013   102901                Shoal Creek Mine     1453024      1237415\n",
      "10  2013   103180             Sloan Mountain Mine      327780       196963\n",
      "11  2013   103182                        Fishtrap      175058        87314\n",
      "12  2013   103285                     Narley Mine      154861        90584\n",
      "13  2013   103332                   Powhatan Mine      140521        61394\n",
      "14  2013   103375                    Johnson Mine         580         1900\n",
      "15  2013   103419               Maxine-Pratt Mine      125824       107469\n",
      "16  2013   103432                   Skelton Creek        8252          220\n",
      "17  2013   103437         Black Warrior Mine No 1      145924        70926\n",
      "18  2013   102976   Piney Woods Preparation Plant           0        14828\n",
      "19  2013   102976   Piney Woods Preparation Plant           0        23193\n",
      "20  2013   103380                          Calera           0        12621\n",
      "21  2013   103380                          Calera           0         1402\n",
      "22  2013   103422                 Clark No 1 Mine      122727       140250\n",
      "23  2013   103467             Helena Surface Mine       59664        30539\n",
      "24  2013   101247                       No 4 Mine     2622528      1551141\n",
      "25  2013   101401                       No 7 Mine     5405412      2464719\n",
      "26  2013   103172  Searles Mine No. 2, 3, 4, 5, 6      258078       119542\n",
      "27  2013   103179             Fleetwood Mine No 1       75937        63745\n",
      "28  2013   103303                    Shannon Mine      317491       164388\n",
      "29  2013   103323                   Deerlick Mine      133452        46381\n",
      "30  2013   103364           Brc Alabama No. 7 Llc           0        14324\n",
      "31  2013   103436                Swann's Crossing      137511        77190\n",
      "32  2013   100347                    Choctaw Mine      537429       215295\n",
      "33  2013   101362                 Manchester Mine      219457       116914\n",
      "34  2013   102996                  Jap Creek Mine      375715       164093\n",
      "35  2013   103155              Corinth Prep Plant           0        27996\n",
      "36  2013   103155              Corinth Prep Plant           0        51994\n",
      "37  2013   103195     Mccollum/Sparks Branch Mine       71910        17411\n",
      "38  2013   103342             Reese's Branch Mine      263888       115123\n",
      "39  2013   103370             Cresent Valley Mine        2860          621\n",
      "40  2013   103372                 Cane Creek Mine       66258        32401\n",
      "41  2013   103376                      Town Creek      299167       176499\n",
      "42  2013   103389                Carbon Hill Mine       76241        84966\n",
      "43  2013   103410                Coal Valley Mine      407841       158591\n",
      "44  2013   103423                Dutton Hill Mine       37275         9162\n",
      "45  2013  1519322                         Ghm #25       25054         3108\n",
      "46  2013   103321                  Poplar Springs      189370        76366\n",
      "47  2013   103358                       Old Union      284563       161805\n",
      "48  2013  5000030                        Usibelli     1631584       286079\n",
      "49  2013   201195                    Kayenta Mine     7602722      1015333>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./coalpublic2013.xlsx')\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a5fb5-6e57-45aa-87da-8e6455d8f3ef",
   "metadata": {},
   "source": [
    "2. Write a Pandas program to get the data types of the given excel data (coalpublic2013.xlsx ) fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a2221ab1-a148-4d5c-8e28-198c153c7978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year            int64\n",
       "MSHA ID         int64\n",
       "Mine_Name      object\n",
       "Production      int64\n",
       "Labor_Hours     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./coalpublic2013.xlsx')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed041935-5af1-464c-b905-dc75c2e20cbc",
   "metadata": {},
   "source": [
    "3. Write a Pandas program to read specific columns from a given excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "78afd786-ad5c-42eb-9434-44ff0edf9094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSHA ID</th>\n",
       "      <th>Mine_Name</th>\n",
       "      <th>Labor_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103381</td>\n",
       "      <td>Tacoa Highwall Miner</td>\n",
       "      <td>22392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103404</td>\n",
       "      <td>Reid School Mine</td>\n",
       "      <td>28447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100759</td>\n",
       "      <td>North River #1 Underground Min</td>\n",
       "      <td>474784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103246</td>\n",
       "      <td>Bear Creek</td>\n",
       "      <td>29193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103451</td>\n",
       "      <td>Knight Mine</td>\n",
       "      <td>46393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>103433</td>\n",
       "      <td>Crane Central Mine</td>\n",
       "      <td>47195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100329</td>\n",
       "      <td>Concord Mine</td>\n",
       "      <td>144002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100851</td>\n",
       "      <td>Oak Grove Mine</td>\n",
       "      <td>1001809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>102901</td>\n",
       "      <td>Shoal Creek Mine</td>\n",
       "      <td>12396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>102901</td>\n",
       "      <td>Shoal Creek Mine</td>\n",
       "      <td>1237415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>103180</td>\n",
       "      <td>Sloan Mountain Mine</td>\n",
       "      <td>196963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>103182</td>\n",
       "      <td>Fishtrap</td>\n",
       "      <td>87314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>103285</td>\n",
       "      <td>Narley Mine</td>\n",
       "      <td>90584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>103332</td>\n",
       "      <td>Powhatan Mine</td>\n",
       "      <td>61394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>103375</td>\n",
       "      <td>Johnson Mine</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>103419</td>\n",
       "      <td>Maxine-Pratt Mine</td>\n",
       "      <td>107469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>103432</td>\n",
       "      <td>Skelton Creek</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>103437</td>\n",
       "      <td>Black Warrior Mine No 1</td>\n",
       "      <td>70926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>102976</td>\n",
       "      <td>Piney Woods Preparation Plant</td>\n",
       "      <td>14828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>102976</td>\n",
       "      <td>Piney Woods Preparation Plant</td>\n",
       "      <td>23193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>103380</td>\n",
       "      <td>Calera</td>\n",
       "      <td>12621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>103380</td>\n",
       "      <td>Calera</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>103422</td>\n",
       "      <td>Clark No 1 Mine</td>\n",
       "      <td>140250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>103467</td>\n",
       "      <td>Helena Surface Mine</td>\n",
       "      <td>30539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>101247</td>\n",
       "      <td>No 4 Mine</td>\n",
       "      <td>1551141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>101401</td>\n",
       "      <td>No 7 Mine</td>\n",
       "      <td>2464719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>103172</td>\n",
       "      <td>Searles Mine No. 2, 3, 4, 5, 6</td>\n",
       "      <td>119542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>103179</td>\n",
       "      <td>Fleetwood Mine No 1</td>\n",
       "      <td>63745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>103303</td>\n",
       "      <td>Shannon Mine</td>\n",
       "      <td>164388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>103323</td>\n",
       "      <td>Deerlick Mine</td>\n",
       "      <td>46381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>103364</td>\n",
       "      <td>Brc Alabama No. 7 Llc</td>\n",
       "      <td>14324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>103436</td>\n",
       "      <td>Swann's Crossing</td>\n",
       "      <td>77190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100347</td>\n",
       "      <td>Choctaw Mine</td>\n",
       "      <td>215295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>101362</td>\n",
       "      <td>Manchester Mine</td>\n",
       "      <td>116914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>102996</td>\n",
       "      <td>Jap Creek Mine</td>\n",
       "      <td>164093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>103155</td>\n",
       "      <td>Corinth Prep Plant</td>\n",
       "      <td>27996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>103155</td>\n",
       "      <td>Corinth Prep Plant</td>\n",
       "      <td>51994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>103195</td>\n",
       "      <td>Mccollum/Sparks Branch Mine</td>\n",
       "      <td>17411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>103342</td>\n",
       "      <td>Reese's Branch Mine</td>\n",
       "      <td>115123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>103370</td>\n",
       "      <td>Cresent Valley Mine</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>103372</td>\n",
       "      <td>Cane Creek Mine</td>\n",
       "      <td>32401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>103376</td>\n",
       "      <td>Town Creek</td>\n",
       "      <td>176499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>103389</td>\n",
       "      <td>Carbon Hill Mine</td>\n",
       "      <td>84966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>103410</td>\n",
       "      <td>Coal Valley Mine</td>\n",
       "      <td>158591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>103423</td>\n",
       "      <td>Dutton Hill Mine</td>\n",
       "      <td>9162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1519322</td>\n",
       "      <td>Ghm #25</td>\n",
       "      <td>3108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>103321</td>\n",
       "      <td>Poplar Springs</td>\n",
       "      <td>76366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>103358</td>\n",
       "      <td>Old Union</td>\n",
       "      <td>161805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5000030</td>\n",
       "      <td>Usibelli</td>\n",
       "      <td>286079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>201195</td>\n",
       "      <td>Kayenta Mine</td>\n",
       "      <td>1015333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSHA ID                       Mine_Name  Labor_Hours\n",
       "0    103381            Tacoa Highwall Miner        22392\n",
       "1    103404                Reid School Mine        28447\n",
       "2    100759  North River #1 Underground Min       474784\n",
       "3    103246                      Bear Creek        29193\n",
       "4    103451                     Knight Mine        46393\n",
       "5    103433              Crane Central Mine        47195\n",
       "6    100329                    Concord Mine       144002\n",
       "7    100851                  Oak Grove Mine      1001809\n",
       "8    102901                Shoal Creek Mine        12396\n",
       "9    102901                Shoal Creek Mine      1237415\n",
       "10   103180             Sloan Mountain Mine       196963\n",
       "11   103182                        Fishtrap        87314\n",
       "12   103285                     Narley Mine        90584\n",
       "13   103332                   Powhatan Mine        61394\n",
       "14   103375                    Johnson Mine         1900\n",
       "15   103419               Maxine-Pratt Mine       107469\n",
       "16   103432                   Skelton Creek          220\n",
       "17   103437         Black Warrior Mine No 1        70926\n",
       "18   102976   Piney Woods Preparation Plant        14828\n",
       "19   102976   Piney Woods Preparation Plant        23193\n",
       "20   103380                          Calera        12621\n",
       "21   103380                          Calera         1402\n",
       "22   103422                 Clark No 1 Mine       140250\n",
       "23   103467             Helena Surface Mine        30539\n",
       "24   101247                       No 4 Mine      1551141\n",
       "25   101401                       No 7 Mine      2464719\n",
       "26   103172  Searles Mine No. 2, 3, 4, 5, 6       119542\n",
       "27   103179             Fleetwood Mine No 1        63745\n",
       "28   103303                    Shannon Mine       164388\n",
       "29   103323                   Deerlick Mine        46381\n",
       "30   103364           Brc Alabama No. 7 Llc        14324\n",
       "31   103436                Swann's Crossing        77190\n",
       "32   100347                    Choctaw Mine       215295\n",
       "33   101362                 Manchester Mine       116914\n",
       "34   102996                  Jap Creek Mine       164093\n",
       "35   103155              Corinth Prep Plant        27996\n",
       "36   103155              Corinth Prep Plant        51994\n",
       "37   103195     Mccollum/Sparks Branch Mine        17411\n",
       "38   103342             Reese's Branch Mine       115123\n",
       "39   103370             Cresent Valley Mine          621\n",
       "40   103372                 Cane Creek Mine        32401\n",
       "41   103376                      Town Creek       176499\n",
       "42   103389                Carbon Hill Mine        84966\n",
       "43   103410                Coal Valley Mine       158591\n",
       "44   103423                Dutton Hill Mine         9162\n",
       "45  1519322                         Ghm #25         3108\n",
       "46   103321                  Poplar Springs        76366\n",
       "47   103358                       Old Union       161805\n",
       "48  5000030                        Usibelli       286079\n",
       "49   201195                    Kayenta Mine      1015333"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "cols = [1, 2, 4]\n",
    "df = pd.read_excel('./coalpublic2013.xlsx', usecols=cols)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92db7b3-7ed8-4d1a-bc84-40927c228338",
   "metadata": {},
   "source": [
    "4. Write a Pandas program to find the sum, mean, max, min value of 'Production (short tons)' column of coalpublic2013.xlsx file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40c27745-b2ba-45e5-83f6-45e9df05c361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum:  27854323\n",
      "Mean:  557086.46\n",
      "Maximum:  7602722\n",
      "Minimum:  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./coalpublic2013.xlsx')\n",
    "print(\"Sum: \",df[\"Production\"].sum()) \n",
    "print(\"Mean: \",df[\"Production\"].mean())\n",
    "print(\"Maximum: \",df[\"Production\"].max())\n",
    "print(\"Minimum: \",df[\"Production\"].min()) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2164e-c71e-40be-8d16-617c21e2e8a3",
   "metadata": {},
   "source": [
    "5. Write a Pandas program to insert a column in the sixth position of the said excel sheet and fill it with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d262b6c-c829-449d-bb84-3a0dbc6c3c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of     Year  MSHA ID                       Mine_Name  column1  Production  \\\n",
      "0   2013   103381            Tacoa Highwall Miner      NaN       56004   \n",
      "1   2013   103404                Reid School Mine      NaN       28807   \n",
      "2   2013   100759  North River #1 Underground Min      NaN     1440115   \n",
      "3   2013   103246                      Bear Creek      NaN       87587   \n",
      "4   2013   103451                     Knight Mine      NaN      147499   \n",
      "5   2013   103433              Crane Central Mine      NaN       69339   \n",
      "6   2013   100329                    Concord Mine      NaN           0   \n",
      "7   2013   100851                  Oak Grove Mine      NaN     2269014   \n",
      "8   2013   102901                Shoal Creek Mine      NaN           0   \n",
      "9   2013   102901                Shoal Creek Mine      NaN     1453024   \n",
      "10  2013   103180             Sloan Mountain Mine      NaN      327780   \n",
      "11  2013   103182                        Fishtrap      NaN      175058   \n",
      "12  2013   103285                     Narley Mine      NaN      154861   \n",
      "13  2013   103332                   Powhatan Mine      NaN      140521   \n",
      "14  2013   103375                    Johnson Mine      NaN         580   \n",
      "15  2013   103419               Maxine-Pratt Mine      NaN      125824   \n",
      "16  2013   103432                   Skelton Creek      NaN        8252   \n",
      "17  2013   103437         Black Warrior Mine No 1      NaN      145924   \n",
      "18  2013   102976   Piney Woods Preparation Plant      NaN           0   \n",
      "19  2013   102976   Piney Woods Preparation Plant      NaN           0   \n",
      "20  2013   103380                          Calera      NaN           0   \n",
      "21  2013   103380                          Calera      NaN           0   \n",
      "22  2013   103422                 Clark No 1 Mine      NaN      122727   \n",
      "23  2013   103467             Helena Surface Mine      NaN       59664   \n",
      "24  2013   101247                       No 4 Mine      NaN     2622528   \n",
      "25  2013   101401                       No 7 Mine      NaN     5405412   \n",
      "26  2013   103172  Searles Mine No. 2, 3, 4, 5, 6      NaN      258078   \n",
      "27  2013   103179             Fleetwood Mine No 1      NaN       75937   \n",
      "28  2013   103303                    Shannon Mine      NaN      317491   \n",
      "29  2013   103323                   Deerlick Mine      NaN      133452   \n",
      "30  2013   103364           Brc Alabama No. 7 Llc      NaN           0   \n",
      "31  2013   103436                Swann's Crossing      NaN      137511   \n",
      "32  2013   100347                    Choctaw Mine      NaN      537429   \n",
      "33  2013   101362                 Manchester Mine      NaN      219457   \n",
      "34  2013   102996                  Jap Creek Mine      NaN      375715   \n",
      "35  2013   103155              Corinth Prep Plant      NaN           0   \n",
      "36  2013   103155              Corinth Prep Plant      NaN           0   \n",
      "37  2013   103195     Mccollum/Sparks Branch Mine      NaN       71910   \n",
      "38  2013   103342             Reese's Branch Mine      NaN      263888   \n",
      "39  2013   103370             Cresent Valley Mine      NaN        2860   \n",
      "40  2013   103372                 Cane Creek Mine      NaN       66258   \n",
      "41  2013   103376                      Town Creek      NaN      299167   \n",
      "42  2013   103389                Carbon Hill Mine      NaN       76241   \n",
      "43  2013   103410                Coal Valley Mine      NaN      407841   \n",
      "44  2013   103423                Dutton Hill Mine      NaN       37275   \n",
      "45  2013  1519322                         Ghm #25      NaN       25054   \n",
      "46  2013   103321                  Poplar Springs      NaN      189370   \n",
      "47  2013   103358                       Old Union      NaN      284563   \n",
      "48  2013  5000030                        Usibelli      NaN     1631584   \n",
      "49  2013   201195                    Kayenta Mine      NaN     7602722   \n",
      "\n",
      "    Labor_Hours  \n",
      "0         22392  \n",
      "1         28447  \n",
      "2        474784  \n",
      "3         29193  \n",
      "4         46393  \n",
      "5         47195  \n",
      "6        144002  \n",
      "7       1001809  \n",
      "8         12396  \n",
      "9       1237415  \n",
      "10       196963  \n",
      "11        87314  \n",
      "12        90584  \n",
      "13        61394  \n",
      "14         1900  \n",
      "15       107469  \n",
      "16          220  \n",
      "17        70926  \n",
      "18        14828  \n",
      "19        23193  \n",
      "20        12621  \n",
      "21         1402  \n",
      "22       140250  \n",
      "23        30539  \n",
      "24      1551141  \n",
      "25      2464719  \n",
      "26       119542  \n",
      "27        63745  \n",
      "28       164388  \n",
      "29        46381  \n",
      "30        14324  \n",
      "31        77190  \n",
      "32       215295  \n",
      "33       116914  \n",
      "34       164093  \n",
      "35        27996  \n",
      "36        51994  \n",
      "37        17411  \n",
      "38       115123  \n",
      "39          621  \n",
      "40        32401  \n",
      "41       176499  \n",
      "42        84966  \n",
      "43       158591  \n",
      "44         9162  \n",
      "45         3108  \n",
      "46        76366  \n",
      "47       161805  \n",
      "48       286079  \n",
      "49      1015333  >\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./coalpublic2013.xlsx')\n",
    "df.insert(3, \"column1\", np.nan)\n",
    "print(df.head) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b294b8b-3086-4f7b-92d5-2796e6d1177f",
   "metadata": {},
   "source": [
    "6. Write a Pandas program to import some excel data (coalpublic2013.xlsx ) skipping first twenty rows into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a498243-c940-460b-8afa-ecf5b56c4ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2013</th>\n",
       "      <th>102976</th>\n",
       "      <th>Piney Woods Preparation Plant</th>\n",
       "      <th>0</th>\n",
       "      <th>23193</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>103380</td>\n",
       "      <td>Calera</td>\n",
       "      <td>0</td>\n",
       "      <td>12621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>103380</td>\n",
       "      <td>Calera</td>\n",
       "      <td>0</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>103422</td>\n",
       "      <td>Clark No 1 Mine</td>\n",
       "      <td>122727</td>\n",
       "      <td>140250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>103467</td>\n",
       "      <td>Helena Surface Mine</td>\n",
       "      <td>59664</td>\n",
       "      <td>30539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>101247</td>\n",
       "      <td>No 4 Mine</td>\n",
       "      <td>2622528</td>\n",
       "      <td>1551141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>101401</td>\n",
       "      <td>No 7 Mine</td>\n",
       "      <td>5405412</td>\n",
       "      <td>2464719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>103172</td>\n",
       "      <td>Searles Mine No. 2, 3, 4, 5, 6</td>\n",
       "      <td>258078</td>\n",
       "      <td>119542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>103179</td>\n",
       "      <td>Fleetwood Mine No 1</td>\n",
       "      <td>75937</td>\n",
       "      <td>63745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>103303</td>\n",
       "      <td>Shannon Mine</td>\n",
       "      <td>317491</td>\n",
       "      <td>164388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>103323</td>\n",
       "      <td>Deerlick Mine</td>\n",
       "      <td>133452</td>\n",
       "      <td>46381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>103364</td>\n",
       "      <td>Brc Alabama No. 7 Llc</td>\n",
       "      <td>0</td>\n",
       "      <td>14324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013</td>\n",
       "      <td>103436</td>\n",
       "      <td>Swann's Crossing</td>\n",
       "      <td>137511</td>\n",
       "      <td>77190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013</td>\n",
       "      <td>100347</td>\n",
       "      <td>Choctaw Mine</td>\n",
       "      <td>537429</td>\n",
       "      <td>215295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013</td>\n",
       "      <td>101362</td>\n",
       "      <td>Manchester Mine</td>\n",
       "      <td>219457</td>\n",
       "      <td>116914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013</td>\n",
       "      <td>102996</td>\n",
       "      <td>Jap Creek Mine</td>\n",
       "      <td>375715</td>\n",
       "      <td>164093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013</td>\n",
       "      <td>103155</td>\n",
       "      <td>Corinth Prep Plant</td>\n",
       "      <td>0</td>\n",
       "      <td>27996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013</td>\n",
       "      <td>103155</td>\n",
       "      <td>Corinth Prep Plant</td>\n",
       "      <td>0</td>\n",
       "      <td>51994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013</td>\n",
       "      <td>103195</td>\n",
       "      <td>Mccollum/Sparks Branch Mine</td>\n",
       "      <td>71910</td>\n",
       "      <td>17411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013</td>\n",
       "      <td>103342</td>\n",
       "      <td>Reese's Branch Mine</td>\n",
       "      <td>263888</td>\n",
       "      <td>115123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013</td>\n",
       "      <td>103370</td>\n",
       "      <td>Cresent Valley Mine</td>\n",
       "      <td>2860</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013</td>\n",
       "      <td>103372</td>\n",
       "      <td>Cane Creek Mine</td>\n",
       "      <td>66258</td>\n",
       "      <td>32401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013</td>\n",
       "      <td>103376</td>\n",
       "      <td>Town Creek</td>\n",
       "      <td>299167</td>\n",
       "      <td>176499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013</td>\n",
       "      <td>103389</td>\n",
       "      <td>Carbon Hill Mine</td>\n",
       "      <td>76241</td>\n",
       "      <td>84966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2013</td>\n",
       "      <td>103410</td>\n",
       "      <td>Coal Valley Mine</td>\n",
       "      <td>407841</td>\n",
       "      <td>158591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2013</td>\n",
       "      <td>103423</td>\n",
       "      <td>Dutton Hill Mine</td>\n",
       "      <td>37275</td>\n",
       "      <td>9162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2013</td>\n",
       "      <td>1519322</td>\n",
       "      <td>Ghm #25</td>\n",
       "      <td>25054</td>\n",
       "      <td>3108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2013</td>\n",
       "      <td>103321</td>\n",
       "      <td>Poplar Springs</td>\n",
       "      <td>189370</td>\n",
       "      <td>76366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013</td>\n",
       "      <td>103358</td>\n",
       "      <td>Old Union</td>\n",
       "      <td>284563</td>\n",
       "      <td>161805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2013</td>\n",
       "      <td>5000030</td>\n",
       "      <td>Usibelli</td>\n",
       "      <td>1631584</td>\n",
       "      <td>286079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2013</td>\n",
       "      <td>201195</td>\n",
       "      <td>Kayenta Mine</td>\n",
       "      <td>7602722</td>\n",
       "      <td>1015333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    2013   102976   Piney Woods Preparation Plant        0    23193\n",
       "0   2013   103380                          Calera        0    12621\n",
       "1   2013   103380                          Calera        0     1402\n",
       "2   2013   103422                 Clark No 1 Mine   122727   140250\n",
       "3   2013   103467             Helena Surface Mine    59664    30539\n",
       "4   2013   101247                       No 4 Mine  2622528  1551141\n",
       "5   2013   101401                       No 7 Mine  5405412  2464719\n",
       "6   2013   103172  Searles Mine No. 2, 3, 4, 5, 6   258078   119542\n",
       "7   2013   103179             Fleetwood Mine No 1    75937    63745\n",
       "8   2013   103303                    Shannon Mine   317491   164388\n",
       "9   2013   103323                   Deerlick Mine   133452    46381\n",
       "10  2013   103364           Brc Alabama No. 7 Llc        0    14324\n",
       "11  2013   103436                Swann's Crossing   137511    77190\n",
       "12  2013   100347                    Choctaw Mine   537429   215295\n",
       "13  2013   101362                 Manchester Mine   219457   116914\n",
       "14  2013   102996                  Jap Creek Mine   375715   164093\n",
       "15  2013   103155              Corinth Prep Plant        0    27996\n",
       "16  2013   103155              Corinth Prep Plant        0    51994\n",
       "17  2013   103195     Mccollum/Sparks Branch Mine    71910    17411\n",
       "18  2013   103342             Reese's Branch Mine   263888   115123\n",
       "19  2013   103370             Cresent Valley Mine     2860      621\n",
       "20  2013   103372                 Cane Creek Mine    66258    32401\n",
       "21  2013   103376                      Town Creek   299167   176499\n",
       "22  2013   103389                Carbon Hill Mine    76241    84966\n",
       "23  2013   103410                Coal Valley Mine   407841   158591\n",
       "24  2013   103423                Dutton Hill Mine    37275     9162\n",
       "25  2013  1519322                         Ghm #25    25054     3108\n",
       "26  2013   103321                  Poplar Springs   189370    76366\n",
       "27  2013   103358                       Old Union   284563   161805\n",
       "28  2013  5000030                        Usibelli  1631584   286079\n",
       "29  2013   201195                    Kayenta Mine  7602722  1015333"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./coalpublic2013.xlsx', skiprows = 20)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e06243-219b-4e84-89b7-9ae7ec3ed0d7",
   "metadata": {},
   "source": [
    "7. Write a Pandas program to add summation to a row of the given excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a806fa80-ba8a-4829-a17a-17802f4d0397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MSHA ID</th>\n",
       "      <th>Mine_Name</th>\n",
       "      <th>Production</th>\n",
       "      <th>Labor_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27854323</td>\n",
       "      <td>11098816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  MSHA ID  Mine_Name  Production  Labor_Hours\n",
       "0   NaN      NaN        NaN    27854323     11098816"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./coalpublic2013.xlsx')\n",
    "sum_row=df[[\"Production\", \"Labor_Hours\"]].sum()\n",
    "df_sum=pd.DataFrame(data=sum_row).T\n",
    "df_sum=df_sum.reindex(columns=df.columns)\n",
    "df_sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526f4ea-bba4-411f-9d30-effda0cbb37c",
   "metadata": {},
   "source": [
    "8. Write a Pandas program to import excel data (coalpublic2013.xlsx ) into a Pandas dataframe and display the last ten rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "586f16c5-2dd2-47d7-aa09-e7c75c6d6c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MSHA ID</th>\n",
       "      <th>Mine_Name</th>\n",
       "      <th>Production</th>\n",
       "      <th>Labor_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2013</td>\n",
       "      <td>103372</td>\n",
       "      <td>Cane Creek Mine</td>\n",
       "      <td>66258</td>\n",
       "      <td>32401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2013</td>\n",
       "      <td>103376</td>\n",
       "      <td>Town Creek</td>\n",
       "      <td>299167</td>\n",
       "      <td>176499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2013</td>\n",
       "      <td>103389</td>\n",
       "      <td>Carbon Hill Mine</td>\n",
       "      <td>76241</td>\n",
       "      <td>84966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2013</td>\n",
       "      <td>103410</td>\n",
       "      <td>Coal Valley Mine</td>\n",
       "      <td>407841</td>\n",
       "      <td>158591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2013</td>\n",
       "      <td>103423</td>\n",
       "      <td>Dutton Hill Mine</td>\n",
       "      <td>37275</td>\n",
       "      <td>9162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2013</td>\n",
       "      <td>1519322</td>\n",
       "      <td>Ghm #25</td>\n",
       "      <td>25054</td>\n",
       "      <td>3108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2013</td>\n",
       "      <td>103321</td>\n",
       "      <td>Poplar Springs</td>\n",
       "      <td>189370</td>\n",
       "      <td>76366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2013</td>\n",
       "      <td>103358</td>\n",
       "      <td>Old Union</td>\n",
       "      <td>284563</td>\n",
       "      <td>161805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2013</td>\n",
       "      <td>5000030</td>\n",
       "      <td>Usibelli</td>\n",
       "      <td>1631584</td>\n",
       "      <td>286079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2013</td>\n",
       "      <td>201195</td>\n",
       "      <td>Kayenta Mine</td>\n",
       "      <td>7602722</td>\n",
       "      <td>1015333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  MSHA ID         Mine_Name  Production  Labor_Hours\n",
       "40  2013   103372   Cane Creek Mine       66258        32401\n",
       "41  2013   103376        Town Creek      299167       176499\n",
       "42  2013   103389  Carbon Hill Mine       76241        84966\n",
       "43  2013   103410  Coal Valley Mine      407841       158591\n",
       "44  2013   103423  Dutton Hill Mine       37275         9162\n",
       "45  2013  1519322           Ghm #25       25054         3108\n",
       "46  2013   103321    Poplar Springs      189370        76366\n",
       "47  2013   103358         Old Union      284563       161805\n",
       "48  2013  5000030          Usibelli     1631584       286079\n",
       "49  2013   201195      Kayenta Mine     7602722      1015333"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./coalpublic2013.xlsx')\n",
    "df.tail(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a336eb65-7e52-4a7e-b2ef-2c2517d63ef6",
   "metadata": {},
   "source": [
    "9. Write a Pandas program to create a subtotal of \"Labor Hours\" against MSHA ID from the given excel data (coalpublic2013.xlsx )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fd737751-49cf-49a2-ab84-369544addd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labor_Hours</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSHA ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100329</th>\n",
       "      <td>144002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100347</th>\n",
       "      <td>215295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100759</th>\n",
       "      <td>474784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100851</th>\n",
       "      <td>1001809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101247</th>\n",
       "      <td>1551141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101362</th>\n",
       "      <td>116914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101401</th>\n",
       "      <td>2464719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102901</th>\n",
       "      <td>1249811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102976</th>\n",
       "      <td>38021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102996</th>\n",
       "      <td>164093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103155</th>\n",
       "      <td>79990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103172</th>\n",
       "      <td>119542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103179</th>\n",
       "      <td>63745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103180</th>\n",
       "      <td>196963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103182</th>\n",
       "      <td>87314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103195</th>\n",
       "      <td>17411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103246</th>\n",
       "      <td>29193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103285</th>\n",
       "      <td>90584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103303</th>\n",
       "      <td>164388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103321</th>\n",
       "      <td>76366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103323</th>\n",
       "      <td>46381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103332</th>\n",
       "      <td>61394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103342</th>\n",
       "      <td>115123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103358</th>\n",
       "      <td>161805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103364</th>\n",
       "      <td>14324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103370</th>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103372</th>\n",
       "      <td>32401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103375</th>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103376</th>\n",
       "      <td>176499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103380</th>\n",
       "      <td>14023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103381</th>\n",
       "      <td>22392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103389</th>\n",
       "      <td>84966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103404</th>\n",
       "      <td>28447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103410</th>\n",
       "      <td>158591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103419</th>\n",
       "      <td>107469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103422</th>\n",
       "      <td>140250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103423</th>\n",
       "      <td>9162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103432</th>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103433</th>\n",
       "      <td>47195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103436</th>\n",
       "      <td>77190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103437</th>\n",
       "      <td>70926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103451</th>\n",
       "      <td>46393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103467</th>\n",
       "      <td>30539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201195</th>\n",
       "      <td>1015333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519322</th>\n",
       "      <td>3108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000030</th>\n",
       "      <td>286079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Labor_Hours\n",
       "MSHA ID             \n",
       "100329        144002\n",
       "100347        215295\n",
       "100759        474784\n",
       "100851       1001809\n",
       "101247       1551141\n",
       "101362        116914\n",
       "101401       2464719\n",
       "102901       1249811\n",
       "102976         38021\n",
       "102996        164093\n",
       "103155         79990\n",
       "103172        119542\n",
       "103179         63745\n",
       "103180        196963\n",
       "103182         87314\n",
       "103195         17411\n",
       "103246         29193\n",
       "103285         90584\n",
       "103303        164388\n",
       "103321         76366\n",
       "103323         46381\n",
       "103332         61394\n",
       "103342        115123\n",
       "103358        161805\n",
       "103364         14324\n",
       "103370           621\n",
       "103372         32401\n",
       "103375          1900\n",
       "103376        176499\n",
       "103380         14023\n",
       "103381         22392\n",
       "103389         84966\n",
       "103404         28447\n",
       "103410        158591\n",
       "103419        107469\n",
       "103422        140250\n",
       "103423          9162\n",
       "103432           220\n",
       "103433         47195\n",
       "103436         77190\n",
       "103437         70926\n",
       "103451         46393\n",
       "103467         30539\n",
       "201195       1015333\n",
       "1519322         3108\n",
       "5000030       286079"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./coalpublic2013.xlsx')\n",
    "df_sub=df[[\"MSHA ID\",\"Labor_Hours\"]].groupby('MSHA ID').sum()\n",
    "df_sub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552cc94b-781a-422b-a1d9-d743219725ab",
   "metadata": {},
   "source": [
    "10. Write a Pandas program to import excel data (coalpublic2013.xlsx ) into a dataframe and find a specific MSHA ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c6dfa11b-9671-4e16-82b1-46e0acea2d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>MSHA ID</th>\n",
       "      <th>Mine_Name</th>\n",
       "      <th>Production</th>\n",
       "      <th>Labor_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>102901</td>\n",
       "      <td>Shoal Creek Mine</td>\n",
       "      <td>0</td>\n",
       "      <td>12396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>102901</td>\n",
       "      <td>Shoal Creek Mine</td>\n",
       "      <td>1453024</td>\n",
       "      <td>1237415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  MSHA ID         Mine_Name  Production  Labor_Hours\n",
       "8  2013   102901  Shoal Creek Mine           0        12396\n",
       "9  2013   102901  Shoal Creek Mine     1453024      1237415"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel('./coalpublic2013.xlsx')    \n",
    "df[df[\"MSHA ID\"]==102901].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f1b013-959b-412c-a617-929b6f3b2985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
